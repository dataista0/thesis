\appendix
\chapter{Herramientas}
\label{chap:herramientas}

\section{Stanford Question Classifier}
\label{sec:stanford-qc}
El Question Classifier de Stanford \cite{QC2} es un sistema de clasificación de preguntas basado en machine learning que utiliza la arquitectura de aprendizaje SNoW. Es un sistema jerárquico guiado por una semántica de dos niveles que permite la clasificación en categorías granulares. Según los tests de los autores, el proceso logra una efectividad del 90\% sobre 50 diferentes clases finales, utilizando features sintácticos y semánticos.

El clasificador dispone de una taxonomía de dos capas basada en los tipos de respuesta típicos de la TREC. Las clases superiores son seis: abreviatura, entidad, descripción, humano, lugar y numérico; divididas a su vez en 50 subclases más finas no solapadas (50 en total). La motivación de la existencia de clases superiores es doble: por un lado, ellas preservan compatibilidad y coherencia con las clases usadas en trabajos previos de clasificación de preguntas. Por otro, se esperaba obtener mejoras de performance aplicando dos fases de clasificación, pero esta intención no se corroboró en la experiencia

La tabla siguiente muestra la taxonomía de clasificación dividida en clases y subclases \footnote{Puede encontrarse en esta url: \url{http://cogcomp.cs.illinois.edu/Data/QA/QC/definition.html} y está explicada en \cite{QC2} y \cite{QC3}}


\begin{center}
\begin{longtable}{| l | l |}
\hline
Clase y subclase & Definición \\ \hline
ABBREVIATION &  abbreviation \\ \hline
  abb & abbreviation\\ \hline
  exp & expression abbreviated\\ \hline
ENTITY  & entities\\ \hline
  animal  & animals\\ \hline
  body & organs of body\\ \hline
  color & colors\\ \hline
  creative & inventions, books and other creative pieces\\ \hline
  currency & currency names\\ \hline
  dis.med. & diseases and medicine\\ \hline
  event & events\\ \hline
  food & food\\ \hline
  instrument & musical instrument\\ \hline
  lang & languages\\ \hline
  letter & letters like a-z\\ \hline
  other & other entities\\ \hline
  plant & plants\\ \hline
  product & products\\ \hline
  religion  & religions\\ \hline
  sport & sports\\ \hline
  substance & elements and substances\\ \hline
  symbol & symbols and signs\\ \hline
  technique & techniques and methods\\ \hline
  term  & equivalent terms\\ \hline
  vehicle & vehicles\\ \hline
  word & words with a special property\\ \hline
DESCRIPTION & description and abstract concepts\\ \hline
  definition & definition of sth.\\ \hline
  description & description of sth.\\ \hline
  manner & manner of an action\\ \hline
  reason & reasons\\ \hline
%\end{tabular}
%\begin{tabular}{| l | l |}
%\hline
HUMAN & human beings\\ \hline
  group & a group or organization of persons\\ \hline
  ind & an individual\\ \hline
  title & title of a person\\ \hline
  description & description of a person\\ \hline
LOCATION & locations\\ \hline
  city & cities\\ \hline
  country & countries\\ \hline
  mountain & mountains\\ \hline
  other & other locations\\ \hline
  state & states\\ \hline
NUMERIC & numeric values\\ \hline
  code  & postcodes or other codes\\ \hline
  count & number of sth.\\ \hline
  date  & dates\\ \hline
  distance &  linear measures\\ \hline
  money & prices\\ \hline
  order & ranks\\ \hline
  other & other numbers\\ \hline
  period  & the lasting time of sth.\\ \hline
  percent & fractions\\ \hline
  speed & speed\\ \hline
  temp & temperature\\ \hline
  size & size, area and volume\\ \hline
  weight & weight\\ \hline
\end{longtable}
\end{center}


Uno de los principales problemas que tuvieron los autores al enfrentarse a clases tan específicas fue la ambigüedad instrínseca de ciertas preguntas. Los siguientes ejemplos de este problema están tomados de \cite{QC2}:
\begin{itemize}
\item What is bipolar disorder? (¿Qué es el desorden bipolar?)
\item What do bats eat? (¿Qué comen los murciélagos?)
\end{itemize}
La primer pregunta puede pertenecer a la clase \textit{definición} o bien a la clase \textit{enfermedad / medicina} y la segunda a \textit{comida}, \textit{planta} o \textit{animal}. Para abordar este problema, el clasificador asigna diferentes clases ponderadas y no una única clase.

Los dos niveles de clasificación están implementados como dos clasificadores simples en secuencia, ambos utilizando el algoritmo Winnow de SNoW. El primero etiqueta la pregunta en función de las clases más generales y el segundo asigna las clases más finas (dentro de las suclases determinadas por la clase del primero).
El modelo para el algoritmo de aprendizaje representa las preguntas como listas de características (\textit{features}) tanto sintácticos como semánticos. Los features utilizando son, en total, más de 200.000, siendo casi todos combinaciones complejas de un set acotado de features simples basados en palabras, pos tags, chunks (componentes constitucionales de la oración), chunks principales (por ejemplo: componente nominal principal), entidades nombradas y palabras semánticamente relacionadas a ciertas clases. De estos seis tipos de features primitivos, tres son sintácticos (pos tags, chunks, chunks principales) mientras que otros son semánticos (named entities, palabras relacionadas).

El clasificador, al igual que el resto de las herramientas de nlp de Stanford, está implementado en java.


\section{Stanford POS \& NER Taggers}
\label{sec:stanford-pos}
\label{sec:stanford-both}
El POS tagger de Stanford es un algortimo basado en entropía máxima (\textit{maximum entropy}), implementado en java originalmente en \cite{POS2}, con algunos agregados y mejoras técnicas realizadas en \cite{POS1}. Al descargar el paquete, también está disponible uno más complejo con soporte para los idiomas árabe, chino y alemán. En este trabajo utilizamos el paquete sencillo, que consta de dos modelos entrenados para inglés, usando, como señalamos en \allref{subsec:pos} el tagset de Penn Treebank.


Por su parte, el NER tagger de Stanford, es una implementación general de

It comes with well-engineered feature extractors for Named Entity Recognition, and many options for defining feature extractors. Included with the download are good named entity recognizers for English, particularly for the 3 classes (PERSON, ORGANIZATION, LOCATION), and we also make available on this page various other models for different languages and circumstances, including models trained on just the CoNLL 2003 English training data. The distributional similarity features in some models improve performance but the models require considerably more memory.

Stanford NER is also known as CRFClassifier. The software provides a general implementation of (arbitrary order) linear chain Conditional Random Field (CRF) sequence models. That is, by training your own models, you can actually use this code to build sequence models for any task. (CRF models were pioneered by Lafferty, McCallum, and Pereira (2001); see Sutton and McCallum (2006) or Sutton and McCallum (2010) for more comprehensible introductions.)

The CRF code is by Jenny Finkel. The feature extractors are by Dan Klein, Christopher Manning, and Jenny Finkel. Much of the documentation and usability is due to Anna Rafferty. The CRF sequence models provided here do not precisely correspond to any published paper, but the correct paper to cite for the software is:

Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp. 363-370. http://nlp.stanford.edu/~manning/papers/gibbscrf3.pdf
The software provided here is similar to the baseline local+Viterbi model in that paper, but adds new distributional similarity based features (in the -distSim classifiers). The big models were trained on a mixture of CoNLL, MUC-6, MUC-7 and ACE named entity corpora, and as a result the models are fairly robust across domains.
Named Entity Recognition Stanford Named Entity Recognizer (Finkel,
Grenager and Manning 2005)

Finkel, Jenny Rose, Trond Grenager, and Christopher Manning. "Incorporating
Non-local Information into Information Extraction Systems by Gibbs Sampling."
roceedings of the 43nd Annual Meeting of the Association for Computational
Linguistics. 2005.



\section{Freeling}
\label{sec:freeling}
\label{subsec:freeling-pos}
\label{subsec:freeling-mods}
Freeling es una librería de c\'odigo abierto que provee distintas herramientas de
procesamiento de lenguaje natural, desarrollada y mantenida por el Centre de Tecnologies
i Aplicacions del Llenguatge i la Parla (TALP) de la Universidad Politécnica de Catalu\~na (UPC).
Freeling está dise\~nado para ser usada como una librería externa y ofrece un API en distintos lenguajes
de programaci\'on. Su principal virtud es ser multilingüe, esto es, los diferentes analizadores que provee funcionan
para un conjunto bastante amplio de idiomas. La última versi\'on a la fecha (3.1) soporta los siguientes idiomas:

\begin{itemize}
\item Asturian (as)
\item Catalan (ca)
\item English (en)
\item French (fr)
\item Galician (gl)
\item Italian (it)
\item Portuguese (pt)
\item Russian (ru)
\item Slovene (sl)
\item Spanish (es)
\item Welsh (cy)
\end{itemize}

Cabe destacar que no todos los m\'odulos soportan todos los idiomas. Sin embargo, dado que el proyecto está radicado en Espa\~na,
los idiomas necesarios para los fines de nuestro trabajo (espa\~nol e inglés), soportan todos los m\'odulos disponibles
en la librería.
Freeling 3.1 ofrece los siguientes analizadores lingüisticos:

\begin{itemize}
\item Detecci\'on de idioma
\item Tokenizer
\item Sentence splitting,
\item Análisis morfol\'ogico
\item NER y NEC (Detecci\'on y Clasificaci\'on de Entidades Nombradas)
\item Reconocimiento de fechas, números, magnitudes físicas, monedas
\item Codificaci\'on fonética
\item POS tagging,
\item Shallow parsing
\item Dependency parsing
\item Wordnet-based sense annotation
\item Word Sense Disambiguation
\item Coreference resolution
\end{itemize}


El módulo de POS tagging de Freeling dispone de dos tagger. El primero, $hmm\_tagger$, es un algoritmo clásico que utiliza Hidden Markov Models (HMMs) con tri-gramas. La descripción del algoritmo de tagging basado en HMM se encuentra con detalle en  en \cite{POS0}. Por otro lado, el módulo incorpora un método llamado $relax\_tagger$ que permite la creación de un sistema híbrido que permite reglas escritas a mano y modelos estadísticos.

\section{Apache Lucene}
\label{sec:lucene}
Lucene es una librería de information retrieval, de c\'odigo abierto, escrita en Java y distribuida
bajo la licencia Apache Software License por la Apache Software Foundation. No está pensada para
usuarios finales sino para ser integrada dentro de proyectos informáticos, resolviendo
la parte de bajo nivel y brindando servicios a través de un API en diferentes lenguajes de programaci\'on.
Su core es un índice invertido como el que describimos anteriormente. La implementaci\'on de un sistema
que utiliza Lucene consta de dos pasos separados:
\begin{itemize}
\item La \textbf{creaci\'on} del índice, es por lo general un proceso offline en el cual
se incorporan distintas fuentes de informaci\'on al índice
\item La \textbf{búsqueda} de documentos en el índice creado en el paso anterior, a partir de una query
ingresada por el usuario final. Este proceso se incorpora dentro del flujo `online' del sistema.
El resultado de esta búsqueda es una lista de documentos rankeados con un cierto puntaje.
\end{itemize}

Es importante señalar que si bien el proceso de creaci\'on del índice suele estar desacoplado del resto
del sistema, las fuentes de informaci\'on no tiene por que ser `offline' en el sentido de ser documentos
en un disco local. De hecho, Nutch, otro proyecto de c\'odigo abierto de la Apache Software Foundation es
un motor de búsqueda web basado en Lucene que incorpora un crawler para indexar sitios web. Lucene soporta
cualquier fuente de informaci\'on que pueda convertirse en texto mediante algoritmia.
\newline
Los conceptos fundamentales de Lucene son: índice, documento, campo, término y query.
\begin{itemize}
\item Un índice contiene un conjunto de documentos
\item Un documento es un conjunto de campos
\item Un campo es el nombre de una secuencia de términos
\item Un término es un token (una palabra)
\item Una query es una lista de términos conectados con distintos operados l\'ogicos
\end{itemize}