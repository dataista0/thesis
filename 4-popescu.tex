\chapter{Implementación de datos estructurados}
\label{chap:4}
En este capítulo, finalmente, nos toca hablar del primero de los dos sistemas implementados en este trabajo.
El sistema en cuestión implementa, con algunas limitaciones que mencionaremos, el modelo de Popescu descripto en \cite{QADB1} y \cite{QADB2} y reseñados por nosotros en \ref{subsec:closed-domain}.

Nuestro código está accesible públicamente en la siguiente dirección: \url{http://github.com/julian3833/popescu-world}. Allí pueden encontrarse, además del código en sí mismo, los procedimientos de instalación, ejemplos de ejecución y una lista con los principales puntos técnicos que pueden mejorarse (ver, también, \allref{subsec:popescu-cierre}).

Testeamos este sistema sobre la base de datos World, en inglés, ofrecida por MySQL\footnote{Ver \url{http://dev.mysql.com/doc/world-setup/en/index.html} y \url{http://dev.mysql.com/doc/index-other.html}} que consta de información geográfica básica sobre países, ciudades e idiomas.

Cabe mencionar que el scope original de este sistema era ser bilingüe y ejecutarse sobre una base de datos sobre universidades, empresas e investigación nacional del ámbito de la informática. Lamentablemente, por una cuestión de tiempos y de errores a la hora de estimar esfuerzos, no pudimos completar este plan original.

La estructura del capítulo es como sigue: En \ref{sec:popescu-db} pasamos revista de la base de datos que utilizamos para implementar el sistema y en \ref{sec:popescu-implementacion} discutimos la implementación. \ref{sec:popescu-implementacion} se divide, a su vez, en \ref{subsec:popescu-codigo}, donde discutimos la implementación en sí misma, \ref{subsec:popescu-ejemplos}, donde mostramos y comentamos algunos ejemplos de ejecuciones y \ref{subsec:popescu-cierre} donde analizamos los alcances, los límites y el trabajo futuro.


\section{Base de datos}
\label{sec:popescu-db}

La base de datos World consta de 3 tablas: Country, City y CountryLanguage (ver Figura \ref{fig:world-db}).

\begin{figure}
  \centering
    %\includegraphics[scale=1.0]{graficos/popescu-example}
    \includegraphics[width=12.823cm,height=8.004cm]{graficos/fuentes/world-db.png}
  \caption{Modelo entidad relación de la base de datos World original}
  \label{fig:world-db}
\end{figure}

La tabla Country tiene información básica acerca de varios países del mundo. La tabla City tiene información sobre las mayores ciudades del mundo y, finalmente, la tabla CountryLanguage tiene información sobre los idiomas hablados en cada país.

Hay una relación de uno a muchos entre Country y CountryLanguage: cada país puede tener más de un idioma y, además, hay una relación de uno a muchos entre Country y City: cada país puede tener más de una ciudad.

\medskip
Las definiciones de las relaciones originales son:
\begin{itemize}
\item Country(Code, Name, Continent, Region, SurfaceArea, IndepYear, Population, LifeExpectancy, GNP, GNPOld, LocalName, GovernmentForm, HeadOfState, Capital, Code2)
\item City(ID, ContryCode, Name, District, Population)
\item CountryLanguage(CountryCode, Language, IsOfficial, Percentage)
\end{itemize}

Para nuestro proyecto, renombramos algunos de los elementos:
\begin{itemize}
\item La relación CountryLanguage fue renombrada a Language
\item El atributo Language de la relación CountryLanguage fue renombrado a Name
\item El atributo IndepYear de la relación Country fue renombrado a IndependenceYear
\end{itemize}

Por otro lado, dado que, por una cuestión de tiempos y de complejidad del desarrollo, no soportamos más de un join posible entre tablas, eliminamos la referencia a la tabla City en el atributo Country.Capital. Lo que hicimos fue rellenar ese campo con el nombre de la ciudad en lugar de su  ID, perdiendo la posibilidad de navegar con preguntas del tipo ¿Cuál es la población de la capital del país X?.
Los JOINS que manejamos, en caso de ser necesarios por estarse refiriendo más de una tabla, son City.CountryCode $=$ Country.Code y Language.CountryCode$=$Country.Code.

En las tablas \ref{table:countrylanguage-data}, \ref{table:city-data}, \ref{tab:country-data} y \ref{tab:country-data-2} pueden verse algunas filas de ejemplo de cada una de las tablas.


 \begin{longtable}{|l|l|l|l|}
 \hline  \multicolumn{1}{|c|}{\textbf{CountryCode}} & \multicolumn{1}{|c|}{\textbf{Language}} & \multicolumn{1}{|c|}{\textbf{IsOfficial}} & \multicolumn{1}{|c|}{\textbf{Percentage}} \\ \hline  \endfirsthead
\caption{Algunas filas de la tabla CountryLanguage (cont)} \\ \hline \multicolumn{1}{|c|}{\textbf{CountryCode}} & \multicolumn{1}{|c|}{\textbf{Language}} & \multicolumn{1}{|c|}{\textbf{IsOfficial}} & \multicolumn{1}{|c|}{\textbf{Percentage}} \\ \hline \hline \endhead \endfoot
ABW & Dutch & T & 5.3 \\ \hline
ABW & English & F & 9.5 \\ \hline
ABW & Papiamento & F & 76.7 \\ \hline
ABW & Spanish & F & 7.4 \\ \hline
AFG & Balochi & F & 0.9 \\ \hline
AFG & Dari & T & 32.1 \\ \hline
AFG & Pashto & T & 52.4 \\ \hline
AFG & Turkmenian & F & 1.9 \\ \hline
AFG & Uzbek & F & 8.8 \\ \hline
AGO & Ambo & F & 2.4 \\ \hline
AGO & Chokwe & F & 4.2 \\ \hline
AGO & Kongo & F & 13.2 \\ \hline
AGO & Luchazi & F & 2.4 \\ \hline
\caption{Algunas filas de la tabla CountryLanguage}
\label{table:countrylanguage-data}
\end{longtable}



  \begin{longtable}{|l|l|l|l|l|}
 \hline \multicolumn{1}{|c|}{\textbf{ID}} & \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{|c|}{\textbf{CountryCode}} & \multicolumn{1}{|c|}{\textbf{District}} & \multicolumn{1}{|c|}{\textbf{Population}} \\ \hline \endfirsthead
\caption{Algunas filas de la tabla city} \\ \hline \multicolumn{1}{|c|}{\textbf{ID}} & \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{|c|}{\textbf{CountryCode}} & \multicolumn{1}{|c|}{\textbf{District}} & \multicolumn{1}{|c|}{\textbf{Population}} \\ \hline \hline \endhead \endfoot
129 & Oranjestad & ABW & – & 29034 \\ \hline
1 & Kabul & AFG & Kabol & 1780000 \\ \hline
56 & Luanda & AGO & Luanda & 2022000 \\ \hline
61 & South Hill & AIA & – & 961 \\ \hline
34 & Tirana & ALB & Tirana & 270000 \\ \hline
55 & Andorra la Vella & AND & Andorra la Vella & 21189 \\ \hline
33 & Willemstad & ANT & Curaçao & 2345 \\ \hline
64 & Dubai & ARE & Dubai & 669181 \\ \hline
69 & Buenos Aires & ARG & Distrito Federal & 2982146 \\ \hline
126 & Yerevan & ARM & Yerevan & 1248700 \\ \hline
53 & Tafuna & ASM & Tutuila & 5200 \\ \hline
63 & Saint John's & ATG & St John & 24000 \\ \hline
130 & Sydney & AUS & New South Wales & 3276207 \\ \hline
 \caption{Algunas filas de la relación City} \label{table:city-data}
 \end{longtable}

\bigskip


\begin{footnotesize}
 \begin{longtable}{|l|l|l|l|l|l|}
 \hline \multicolumn{1}{|c|}{\textbf{Code}} & \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{|c|}{\textbf{Continent}} & \multicolumn{1}{|c|}{\textbf{Region}} & \multicolumn{1}{|c|}{\textbf{SurfaceArea}} & \multicolumn{1}{|c|}{\textbf{IndepYear}} \\ \hline \hline  \endfirsthead
\caption{Algunas filas de la tabla Country} \\ \hline \multicolumn{1}{|c|}{\textbf{Code}} & \multicolumn{1}{|c|}{\textbf{Name}} & \multicolumn{1}{|c|}{\textbf{Continent}} & \multicolumn{1}{|c|}{\textbf{Region}} & \multicolumn{1}{|c|}{\textbf{SurfaceArea}} & \multicolumn{1}{|c|}{\textbf{IndepYear}} \\ \hline \hline \endhead \endfoot
ABW & Aruba & North America & Caribbean & 193.00 & \textit{NULL} \\ \hline
AFG & Afghanistan & Asia & Southern and Central Asia & 652090.00 & 1919 \\ \hline
AGO & Angola & Africa & Central Africa & 1246700.00 & 1975 \\ \hline
AIA & Anguilla & North America & Caribbean & 96.00 & \textit{NULL} \\ \hline
ALB & Albania & Europe & Southern Europe & 28748.00 & 1912 \\ \hline
AND & Andorra & Europe & Southern Europe & 468.00 & 1278 \\ \hline
ANT & Netherlands Antilles & North America & Caribbean & 800.00 & \textit{NULL} \\ \hline
ARE & United Arab Emirates & Asia & Middle East & 83600.00 & 1971 \\ \hline
ARG & Argentina & South America & South America & 2780400.00 & 1816 \\ \hline
ARM & Armenia & Asia & Middle East & 29800.00 & 1991 \\ \hline
ASM & American Samoa & Oceania & Polynesia & 199.00 & \textit{NULL} \\ \hline
ATA & Antarctica & Antarctica & Antarctica & 13120000.00 & \textit{NULL} \\ \hline
ATF & French Southern territories & Antarctica & Antarctica & 7780.00 & \textit{NULL} \\ \hline
 \caption{Algunas filas de la tabla Country} \label{tab:country-data}
 \end{longtable}
  \end{footnotesize}

\begin{footnotesize}
 \begin{longtable}{|l|l|p{2cm}|l|p {3cm}| p {3cm}|l|}
 \hline \multicolumn{1}{|c|}{\textbf{Code}} & \multicolumn{1}{|c|}{\textbf{Population}} & \multicolumn{1}{|p{2cm}|}{\textbf{Life Expectancy}} & \multicolumn{1}{|c|}{\textbf{GNP}} & \multicolumn{1}{|p {3cm}|}{\textbf{GovernmentForm}} & \multicolumn{1}{|p {3cm}|}{\textbf{HeadOfState}} & \multicolumn{1}{|c|}{\textbf{Capital}} \\ \hline \hline  \endfirsthead
\caption{Algunas filas de la tabla Country (continuación)} \\ \hline \multicolumn{1}{|c|}{\textbf{Code}} & \multicolumn{1}{|c|}{\textbf{Population}} & \multicolumn{1}{|c|}{\textbf{LifeExpectancy}} & \multicolumn{1}{|c|}{\textbf{GNP}} & \multicolumn{1}{|c|}{\textbf{GovernmentForm}} & \multicolumn{1}{|c|}{\textbf{HeadOfState}} & \multicolumn{1}{|c|}{\textbf{Capital}} \\ \hline \hline \endhead \endfoot
ABW & 103000 & 78.4 & 828.00 & Nonmetropolitan Territory of The Netherlands & Beatrix & 129 \\ \hline
AFG & 22720000 & 45.9 & 5976.00 & Islamic Emirate & Mohammad Omar & 1 \\ \hline
AGO & 12878000 & 38.3 & 6648.00 & Republic & José Eduardo dos Santos & 56 \\ \hline
AIA & 8000 & 76.1 & 63.20 & Dependent Territory of the UK & Elisabeth II & 62 \\ \hline
ALB & 3401200 & 71.6 & 3205.00 & Republic & Rexhep Mejdani & 34 \\ \hline
AND & 78000 & 83.5 & 1630.00 & Parliamentary Coprincipality &  & 55 \\ \hline
ANT & 217000 & 74.7 & 1941.00 & Nonmetropolitan Territory of The Netherlands & Beatrix & 33 \\ \hline
ARE & 2441000 & 74.1 & 37966.00 & Emirate Federation & Zayid bin Sultan al-Nahayan & 65 \\ \hline
ARG & 37032000 & 75.1 & 340238.00 & Federal Republic & Fernando de la Rúa & 69 \\ \hline
ARM & 3520000 & 66.4 & 1813.00 & Republic & Robert Kotšarjan & 126 \\ \hline
 \caption{Algunas filas de la tabla Country (continuación)} \label{tab:country-data-2}
 \end{longtable}
 \end{footnotesize}



Incorporando estos datos al modelo teórico, hasta aquí tenemos definidos: la base de datos, sus elementos ($E$) y el tipo de sus elementos.


\section{Implementación}
\label{sec:popescu-implementacion}


Estructuramos esta sección como sigue. Primero (\ref{subsec:popescu-codigo}), discutimos la implementación en sí misma, analizando los módulos más importantes del sistema, luego (\ref{subsec:popescu-ejemplos}) mostramos y comentamos algunos ejemplos de ejecuciones y, finalmente (\ref{subsec:popescu-cierre}), analizamos alcances, límites y trabajo futuro.

Este apartado es probablemente el más áspero y técnico de la tesis. Si la cantidad de conceptos presentada se vuelve demasiado difícil de retener al lector, recomendamos saltear la sección de \allref{subsec:popescu-codigo} y comenzar por \allref{subsec:popescu-ejemplos}, o bien darle una primera lectura aproximativa a \ref{subsec:popescu-codigo}, pasar a los ejemplos un principio más por arriba y luego sí leer en detalle \ref{subsec:popescu-codigo}.

\subsection{Código}
\label{subsec:popescu-codigo}

\subsubsection*{Lexicón}
\label{subsubsec:lexicon}
El lexicón, recordemos, es el módulo encargado de generar un conjunto de tokens para cada  elemento de la base de datos. Una vez construido este conjunto, las responsabilidades del módulo son las siguientes:
\begin{itemize}
	\item Dado un lema, devolver el conjunto de tokens que lo contienen
	\item Dado un token, devolver el conjunto de elementos de la base de datos que le \textit{corresponden}.
\end{itemize}

El lexicón está implementado en la clase $uba.modules.Lexicon$. Debemos distinguir los momentos de construcción y de consulta del mismo. La construcción, cuyo punto de entrada es el módulo $uba.app.CreateLexicon$, ocurre por separado, y debe ejecutarse una vez antes de poder utilizar el sistema para responder preguntas. Esta genera 4 archivos con formato json, que son luego cargados en memoria al momento de realizar consultas.

En el centro la construcción del lexicón se encuentra Wordnet, una base de datos léxica en inglés, que consta de conjuntos de sinónimos, definiciones de los mismos y relaciones semánticas entre ellos. Utilizamos esta base de datos para obtener los sinónimos de los elementos de la base de datos.

El input del algoritmo es la lista de los elementos de la base de datos (relaciones, atributos y valores) como strings. El primer paso es eliminar el camel case y separar y lematizar las palabras (la tokenizamos en el sentido dado por Popescu a token). Por ejemplo, después de este paso, el elemento GovernmentForm se convierte en el token \{government, form\}. En este paso eliminamos también las stopwords (por ejemplo, HeadOfState se convierte en \{head, state\}).

Luego, los datos pasan por el TokenAugmenter, que simplemente agrega algunos sinónimos escritos a mano a algunos de estos elementos (ver tabla \ref{table:token-augmenter}). Por ejemplo, para el elemento ``region'' (atributo de la relación ``country''), agregamos el término ``location'', para el elemento ``surface area'' agregamos los términos ``total size'' y ``square kilometers''. Este paso es llevado a cabo por la clase $uba.db.TokenAugmenter$ y su intención es mejorar las chances de obtener sinónimos útiles a partir de wordnet, ampliando su input de trabajo. Al salir del TokenAugmenter tenemos, para cada elemento de la base de datos, un conjunto (que puede tener un solo string si el TokenAugmenter no tenía ningún sinónimo) de tokens (que son, a su vez, listas de lemas).

\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| l |  p{12cm} |}
\hline
Elemento original & Sinónimos \\ \hline
head of state & president, leader, emperor, king \\ \hline
region & location\\ \hline
surface area & size, total size, square kilometers, km2\\ \hline
independence year & independent, independency\\ \hline
\end{tabular}
\caption{Sinónimos introducidos por el Token Augmenter}
\label{table:token-augmenter}
\end{table}
\end{center}

El tercer paso es el central: en este se obtienen, para cada uno de estos tokens, tokens sinónimos. Para esto obtenemos una lista de sinónimos y palabras relacionadas para cada lema del token, luego los combinamos formando todos los sinónimos ordenados. Por ejemplo, si el token original consistía de los lemas (A, B) y para A obtuvimos los sinónimos \{A1, A2\} y para B los sinónimos \{B1 y B2\}, el resultado serán todas las combinaciones ordenadas posibles: \{(A, B), (A, B1), (A, B2), (A1, B), (A1, B1), (A1, B2), (A2, B), (A2, B1), (A2, B2)\}.

Finalmente, intentamos obtener sinónimos también de todas las palabras del token juntas (incluyendo las stopwords), ya que verificamos empíricamente que para algunas de ellas existía una entrada en wordnet (Por ejemplo ``head of state'' produce el sinónimo ``chief of state'' que se pierde sin este paso).

El conjunto de tokens sinónimos para cada elementos de la base de datos es luego invertido, es decir, en lugar de disponer de un mapeo de elementos de la base de datos a conjunto de tokens sinónimos, construimos un mapeo de tokens en elementos de la base de datos.

Vale mencionar que en este índice invertido agregamos también tokens para cada qword posible, mapeando a un solo elemento especial, de tipado similar a un valor (WhValue), mediante el cual los tokens de qwords acceden al espacio de elementos de la base de datos. Además, para estos WhValues definimos a mano la relación de compatibilidad con atributos de la base de datos tal como se define en los papers. Esta relación está definida en la clase $uba.db.WhGenerator$ tal como la presentamos en la tabla \ref{table:atributos-qwords}.

El proceso del Lexicón se hace offline y con él queda construido el espacio semántico disponible para comprender palabras.

\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| l |  p{12cm} |}
\hline
Qword & Atributos relacionados \\ \hline
What & \textbf{Name}, District, Population, Code, Continent, SurfaceArea, LifeExpectancy, GNP, LocalName, GovernmentForm,
                         Capital, IsOfficial, Percentage, Region \\ \hline
Which & Los mismos que para what\\ \hline
Where & \textbf{Region}, Continent, Capital, District\\ \hline
Who & \textbf{HeadOfState}\\ \hline
When & \textbf{IndependenceYear}\\ \hline
\end{tabular}
\caption{Atributos compatibles con cada Qword}
\label{table:atributos-qwords}
\end{table}
\end{center}

A partir de este mapeo son generadas algunas estructuras utilizadas para optimizar la performance del sistema, pero sin valor teórico (por ejemplo, la lista de todos los tokens, que es también el conjunto de índices del índice invertido). Estos datos son finalmente grabados en 4 archivos, que son luego cargados a memoria en el sistema principal.

Desde la perspectiva de la lectura, las operaciones son triviales. La interfaz de servicios ofrece los métodos getTokens() y getMatchingElements(). getTokens() es la encargada de devolver, para un lema, el conjunto de tokens que lo contienen, mientras que getMatchingElements() es la encargada de devolver, dado un token, el conjunto de elementos de la base de datos que le corresponden.

Discutamos ahora la implementación del tercer paso, en el que se obtienen sinónimos y palabras relacionadas para cada lema y luego se combinan.

En el caso ideal, lo que se busca es lograr un conjunto de sinónimos para una serie de palabras. Pero lo que entendemos por conjunto de sinónimos se ve opacado por un fenómeno lingüístico conocido como polisemia que es, en algún sentido, un fenómeno inverso a la sinonimia. Al utilizar wordnet siempre existe este problema. La polisemia refiere al hecho de que una palabra puede tener más de un sentido. Es el caso de la palabra banco, que puede ser tanto un asiento en una plaza como una institución financiera. La polisemia es un fenómeno que ocurre en el espacio de relaciones entre las palabras y los conceptos, al igual que la sinonimia, que refiere al hecho de que diferentes palabras pueden referir al mismo concepto (inodoro y retrete). En el core de wordnet existe el tipo de dato synset (conjunto de sinónimos, a veces traducido como anillo de sinónimos), en el que se agrupan, bajo un sentido o concepto, todas las palabras que lo refieren.

En general, los humanos podemos distinguir qué sentido de una palabra polisémica está en uso por contexto. Entre nuestras funciones cognitivas está el reconocer que si alguien dice ``voy a hacer un depósito al banco'', nosotros entendamos que banco, en este contexto, refiere a la institución financiera y no al asiento de plaza. Pero sin contexto es imposible saber de qué sentido se está hablando.

Este problema no es tematizado en los trabajos de Popescu y, sin embargo, ellos argumentan que el sistema Precise fue construido con wordnet (sin  mencionar ningún tipo de desambiguador contextual previo).
En realidad, existe un atenuante para este problema que es el contexto de uso y el rol que cumplen los conjuntos de sinónimos y es que el conjunto de todos los tokens sinónimos generados funciona como un filtro sobre consultas del usuario y nunca es activo o productivo.
Consideremos, por ejemplo, una base de datos sobre localización de sucursales de bancos y el elemento Banco (por ejemplo, el nombre de una relación).
Buscando en sinonimos.com obtenemos los siguientes sinónimos, separados en dos líneas: 1) entidad crediticia, 2) taburete, escabel, escaño, peana, sitial, asiento. Tomando todos los sinónimos tendríamos el siguiente conjunto de sinónimos: \{banco, entidad crediticia, taburete, escaño, peana, sitial, asiento\} donde hay, mezclados, dos sentidos. Ahora bien: ¿qué uso hacemos de este conjunto? El usuario de una aplicación sobre localización de bancos introduce una pregunta, el sistema la separa, lematiza y chequea si los lemas pertenecen a algún conjunto de sinónimos. En este contexto, ¿es un problema que tengamos el término ``asiento'' en nuestro conjunto de sinónimos? Sería un problema solo si el usuario pudiese introducirlo, ya que al conjunto de sinónimos solo se accede a partir de palabras introducidas por el usuario. Si bien este problema es posible, no es probable y, quizás, siguiendo este razonamiento, quienes propusieron el modelo no hicieron ningún énfasis en él.

Nuestro sistema no introduce ningún desambiguador de sentido: utilizamos todo los sinónimos disponibles de tipo sustantivo, introduciendo potenciales errores de interpretación en este punto, con la salvedad recién mencionada.


Finalmente, agregamos también derivaciones léxicas lematizadas. Una derivación léxica es una variación de la palabra original que da otro sentido (relacionado) a la palabra original. Por ejemplo: existir, existencia, existencial, existiendo, existente son una serie de variaciones de la misma raíz.  Esta opción es experimental y puede activarse o desactivarse desde el archivo de configuración ($uba.app.Config$)

En la tabla \ref{table:sinonimos} pueden verse algunos ejemplos de los resultados.

\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| l |  p{9.5cm} | p{4cm} |} \hline
Lema & Sinónimos & Derivaciones léxicas\\ \hline
city 	&	metropolis, (urban, center)	&	citify, metropolitan\\ \hline
country	&	state, nation, land, commonwealth, res publica, body politic, rural area, area	&	--\\ \hline
language	&	language, linguistic communication, speech, speech communication, spoken communication, spoken language, voice communication, oral communication, lyric, words, linguistic process, terminology, nomenclature & lyricist, lyric, speak, terminological \\ \hline
region	&	region, part, area, neighborhood, realm	&	--\\ \hline
location	&	location, placement, locating, position, positioning, emplacement, localization, localisation, fix	&	locate, position, posit, emplace, localize, localise\\ \hline
continent	&	--	&	continental\\ \hline
gnp	&	gross national product	&	--\\ \hline
government	&	government, authorities, regime, governing, governance, government activity, administration, politics, political science	&	govern, political scientist\\ \hline
form	&	form, word form, signifier, descriptor, kind, sort, variety, shape, pattern, configuration, contour, conformation, human body, physical body, material body, soma, build, figure, physique, anatomy, bod, chassis, frame, flesh, cast, variant, strain, var., phase, class, grade, course, mannequin, manikin, mannikin, manakin	&	signify, sort, form, shape, pattern, contour, anatomic, anatomist, anatomical, shapely, variant\\ \hline
\end{tabular}
\caption{Lemas, sinónimos y derivaciones léxicas}
\label{table:sinonimos}
\end{table}
\end{center}

\subsubsection*{Tokenizer}
\label{subsubsec:tokenizer}

El Tokenizer en el modelo de Popescu, recordemos, es el encargado de generar todas las tokenizaciones completas de la pregunta y, para cada token, consultar al Lexicon y retornar la lista de elementos de la base de datos que le corresponden.

\medskip

El Tokenizer sigue el siguiente procedimiento:
\begin{enumerate}
\item Separar la pregunta en palabras, eliminar puntuaciones y pasar a lower case.
\item Lematizar las palabras. Para esto usamos Freeling
\item Eliminar marcadores sintácticos.
\item Para cada lema, obtener todos los tokens que lo contienen del Lexicon (método getTokens).
\item Para cada token potencial (resultado del paso anterior) verificar que todos sus lemas estén presentes en el conjunto de lemas de la pregunta original.
\item Generar el conjunto de partes de todos los tokens hasta aquí obtenidos\footnote{El conjunto de partes de un conjunto dado es otro conjunto formado por todos los subconjuntos del mismo. Por ejemplo, el conjunto de partes de A = \{1, 2, 3\} es: \{ $\varnothing$, \{1\}, \{2\}, \{3\}, \{1, 2\}, \{2, 3\}, \{1, 3\}, \{1, 2, 3\} \}}. \\ \\
	Probando con cada elemento del conjunto de partes en lugar de utilizar solamente el conjunto original podemos obtener subconjuntos que cumplan también la condiciones requeridas para considerarse una tokenización completa (evaluados en 7).
\item Para cada uno de estos subconjuntos, verificar 1) que sus tokens cubran completamente los lemas significativos de la pregunta original y 2) que no haya lemas repetidos entre los tokens.
\end{enumerate}

El resultado será un conjunto de tokenizaciones completas. Como se ve, respetamos casi al pie de la letra la implementación sugerida por Popescu. La obtención de los elementos de la base de datos que corresponden a los elementos, por una cuestión implementativa, quedó en manos del Matcher y no del Tokenizer. La implementación, de todos modos, del servicio, está en el Lexicon. Con este conjunto de tokenizaciones completas como input, será responsabilidad del Matcher decidir cuáles de ellas son traducciones válidas.

\subsubsection*{Matcher}
\label{subsubsec:matcher}

El Matcher, por su parte, toma las tokenizaciones completas generadas por el Tokenizer, construye el grafo que expusimos en la sección \ref{subsec:closed-domain} y ejecuta el algoritmo de max flow. El problema de max-flow es un problema de grafos que consiste en “enviar” el máximo flujo posible a través de un grafo dirigido con dos nodos especiales (fuente o source y sumidero o sink) y aristas con cierta capacidad mayor o igual que cero. Este flujo debe ir desde el nodo fuente al nodo sumidero, respetando las capacidades de las aristas y respetando que, para cada nodo, el flujo saliente no puede ser mayor al flujo entrante.

Existen diferentes algoritmos para resolver este problema. En nuestra implementación, tomamos un código libre disponible en internet (aquí: \url{http://web.mit.edu/~ecprice/acm/acm08/MaxFlow.java}).

Las aristas implicadas en el flujo máximo posible asocian 1) los tokens de valor y de atributo y los correspondientes elementos (valores y atributos, respectivamente) de la base de datos y 2) pares de valores y atributos entre sí.

Después de esto, buscamos otras soluciones posibles de máximo flujo, dado que cualquier solución que tenga como valor para el máximo flujo la cantidad de tokens de valor en la pregunta es, potencialmente, una traducción válida. Para hacer esto retiramos, ordenadamente, las aristas del grafo que ocurren entre la columna 2 y 3 (tokens de valor y valores de la db).

Cabe notarse aquí, como ya mencionamos anteriormente, que no soportamos en nuestra implementación la desambiguación de tokens de relación. Esto significa que: asumimos que un token de relación tiene un solo elemento relación asociado y no será necesario decidir si refiere a una relación u a otra. En todos los ejemplos de bases de datos que consideramos, esta asunción era verdadera (es decir, no existía un token de relación que necesite ser desambiguado) y por ello no implementamos esta capacidad del sistema, que quedará como trabajo futuro. Así mismo, no soportamos tokens multi tipados, prefiriendo relaciones sobre atributos y valores y atributos sobre valores (el caso implementativo es simple: require un grafo extra por cada combinación de tipos distintos por token). Los casos en que esta ambigüedad ocurría eran específicos y la solución no reportaba ninguna mejora cualitativa, por lo que lo dejamos de lado, quedando como una mejora futura.

\medskip

Finalmente, verificamos cuales de las soluciones con máximo flujo cumplen las condiciones requeridas para ser una traducción válida según enunciamos en \ref{subsec:closed-domain}:

\begin{enumerate}
\item Todos  los tokens de la tokenización tienen un único elemento de la base de datos asociado y no hay elementos de la base de datos repetidos. (Mapping.meetsConditionOne())
\item Cada token de atributo se relaciona con un único token de valor respetando que: (Mapping.meetsConditionTwo())
\begin{enumerate}
\item el atributo relacionado con el token de atributo y el valor relacionado con el token de valor son compatibles (esta condición está garantizada por el max-flow mismo)
\item ambos tokens están sintácticamente asociados
\end{enumerate}
\item Cada token de relación está relacionado a un token de atributo o bien a un token de valor, cumpliendo las siguientes condiciones: (Mapping.meetsConditionThree())
\begin{enumerate}
\item	la relación de la base de datos que corresponde al token de relación y el elemento de la base de datos que corresponde al token de atributo o token de valor son compatibles
\item ambos tokens (token de relación - token de atributo o bien token de relación - token de valor) están sintácticamente asociados
\end{enumerate}
\item La pregunta tiene una qword (Mapping.hasOneWhValue())
\end{enumerate}

Notemos que la condición 3 implica que para cada token de relación exista algún token de atributo o de valor a) compatible y b) sintácticamente asociado. La condición a) no está verificada por el algoritmo de máximo flujo y es verificada en el método Mapping.valid()

Para verificar las condiciones de asociación sintáctica (2.b y 3.b) utilizamos la implementación oficial del árbol sintáctico de Charniak (\url{github.com/BLLIP/bllip-parser}), con un wrapper en java que es la clase $uba.nlp.CharniakParseTree$. Las reglas sintácticas utilizadas por Precise no están especificadas en los trabajos, por lo que creamos nuestras propias reglas tomando los ejemplos de asociaciones sintácticas dadas en los trabajos, evaluando los resultados de diferentes ejemplos y extrapolando reglas a partir de allí.


Veamos, en primer lugar, ejemplos del parse tree para tres preguntas:


\begin{center}
\Tree [.S1 [.SBARQ [.WHNP [.WP What ] ] [.SQ [.VP [.AUX are ] [.NP [.DT the ] [.NNP HP ] [.NNS jobs ] ] [.PP [.IN on ] [.NP [.DT a ] [.NNP Unix ] [.NN system ] ] ] ] ] [.. ? ] ] ] \\
``What are the HP jobs on a Unix system?''
\end{center}

\begin{center}

\Tree [.S1 [.SBARQ [.WHNP [.WP What ] ] [.SQ [.VP [.AUX are ] [.NP [.NP [.DT the ] [.NNS capitals ] ] [.PP [.IN of ] [.NP [.DT the ] [.NNP US ] [.NNS states ] ] ] ] ] ] [.. ? ] ] ] \\
``What are the capitals of the US states?''
\end{center}


\begin{center}
\Tree [.S1 [.SBARQ [.WHNP [.WP What ] ] [.SQ [.VP [.AUX are ] [.NP [.NP [.DT the ] [.NNS names ] ] [.PP [.IN of ] [.NP [.NP [.NNS cities ] ] [.PP [.IN of ] [.NP [.NNP Argentina ] ] ] ] ] ] ] ] [.. ? ] ] ]\\
``What are the names of cities of Argentina?''
\end{center}

En las figuras \ref{fig:word-tags} y \ref{fig:syntax-tags} pueden verse los diferentes tags para hojas y para nodos intermedios (respectivamente).


\begin{figure}[H]
  \centering
    \includegraphics[width=12.823cm,height=8.004cm]{graficos/fuentes/WordTags.png}
  \caption{POS tags de Penn Treebank}
  \label{fig:word-tags}
\end{figure}


\begin{figure}[H]
  \centering
    \includegraphics[width=12.823cm,height=8.004cm]{graficos/fuentes/SyntaxTags.png}
  \caption{Conjunto de tags para nodos intermedios del árbol sintáctico}
  \label{fig:syntax-tags}
\end{figure}


Las reglas que construimos son las siguientes (notar que los nombres pueden denotar una direccionalidad, pero las relaciones son simétricas).
Utilizamos NNx para denotar cualquier hoja sustantivo, adjetivo o adverbio (JJ, JJR, JJS, NN, NNS, NNP, NNPS, RB, RBR, RBS, CD), NN para denotar estrictamente sustantivos (NN, NNS, NNP, NNPS), Nx para denotar cualquier sintagma relacionado a estos tipos de hojas (nodos intermedios): (ADJP, ADVP, NP, S) y Wx para denotar alguna de estas hojas: WDT, WP, WP\$ y WRB.

\begin{enumerate}
\item Hermanos:
  \begin{itemize}
    \item  NNx $\Leftrightarrow$ NNx $\Leftrightarrow$ Wx si comparten el mismo el mismo padre
  \end{itemize}
\item Qwords a sustantivo:
  \begin{itemize}
    \item Una Wx dentro de un WHNP $\Rightarrow$ un NN dentro de uno o más Nx dentro de un VP dentro de un SQ con el mismo SBARQ como padre que la WHNP mencionada.
  \end{itemize}
\item Sintagma nominal a sintagma preposicional:
  \begin{itemize}
    \item NN dentro de un Nx (1) $\Rightarrow$ NNx dentro de uno o más Nx dentro de un PP con el mismo padre que el Nx marcado con el (1)
  \end{itemize}
\item Sintagma nominal a sintagma verbal
    \begin{itemize}
      \item NN dentro de un Nx (1) $\Rightarrow$ NNx dentro de uno o más Nx dentro de un VP del mismo padre que el Nx marcado con el (1)
    \end{itemize}
\item Sintagma preposicional a sintagma preposicional:
  \begin{itemize}
    \item NNx dentro de un PP (1) $\Rightarrow$ NNx dentro de uno o más Nx dentro de un PP con el mismo padre que el PP marcado con el (1)
  \end{itemize}
  \item Términos a tokens:
  \begin{itemize}
    \item Dos tokens están asociados si cualquier término de uno está asociado a cualquier término de otro.
  \end{itemize}
\end{enumerate}

En los ejemplos presentados, los pares de términos asociados según estas reglas son los siguientes. Para el primero, (hp, jobs), (unix, system)  (regla 1), (what, hp), (what, jobs) (regla 2) y, finalmente, (hp, unix), (hp, system), (job, unix), (jobs, system) (regla 3). Para el segundo, (us, states) (regla 1), (what, capitals) (regla 2) y (capitals, us) y (capitals, states) (regla 3). Para el tercero, (what, names) (regla 2), (names, cities) y (cities, argentina) (regla 3).
\newline

La definición de las reglas se hizo a prueba y error y es posible que sea simple, para alguien con mayores conocimientos lingüísticos, mejorarlas. Probablemente tenga sentido diferenciar entre sustantivos principal y modificador (Unix y system, por ejemplo) y modificar las reglas 3 y 4 para conectar solo los principales, entre otras mejoras. El sistema ofrece también la opción de no evaluar las asociaciones sintácticas en absoluto, en cuyo caso se mejora la performance pero aparecen nuevas traducciones válidas que podrían haber sido filtradas por estas condiciones, que el usuario deberá desambiguar manualmente).
Además, estas reglas seguramente sean insuficientes y estén dejando afuera varias preguntas que deberían poder procesarse.

Finalmente, todos los resultados de max-flow que cumplen con las condiciones de 1 a  4 son traducciones válidas, que pasan al MappingFilter, que realiza ciertos filtrados que describiremos, de nuevo, en un título aparte.

El resultado de este módulo es una lista de Mappings (una estructura que contiene 1) una tokenización completa de la pregunta original y 2) un mapeo válido entre cada token de la misma en un elemento de la base de datos). Cada mapeo es una traducción válida de la pregunta. Si existe solo uno, entonces este mapeo se traducirá en una query que generará el resultado. Si no, corresponde al MappingFilter realizar filtrados inteligentes de las múltiples soluciones y, en caso de que continúen existiendo múltiples soluciones, entonces se consultará al usuario qué quiso preguntar. Por otro lado, si no fue posible generar ninguna traducción válida, se retornará al usuario sin respuesta, pidiéndole que vuelva a escribir su pregunta de otro modo.

\subsubsection*{MappingFilter}
\label{subsubsec:mapping-filter}

La clase $uba.app.MappingFilter$ es responsable, en primer lugar, de quitar las traducciones válidas repetidas y, en segundo lugar, de aplicar una serie de reglas también de filtrado. Para eliminar las traducciones repetidas, las transformamos en queries y simplemente comparamos por igualdad, ya que el generador de queries ordena las cláusulas generando, para inputs iguales pero diferentemente ordenados, la misma query.
Además de este filtro, aplicamos tres reglas más, de creación propia. En primer lugar, eliminamos ``semi duplicados'', que consisten en atributos similares en la base de datos, en concreto, para esta base de datos, consideramos semi-duplicada a una query que consulta por Country.Name y por Country.LocalName solamente. Veremos más sobre los motivos de esto al presentar las corridas sobre las preguntas de test. La segunda y la tercera regla están basadas en la siguiente idea: en el caso en que exista más de una traducción válida en la cual la qword esté asociada con un atributo \textit{implícito}, por como está el sistema definido, también estará asociado con todos los atributos que pueda estarlo (ver tabla \allref{table:atributos-qwords} para las compatibilidades definidas). Esto implica que, por ejemplo, para cualquier pregunta cuya qword sea 'what' y no tenga su atributo asociado explícito, habrá 16 diferentes traducciones válidas. En los trabajos sobre los que basamos nuestro proyecto este problema no está mencionado y en los ejemplos presentados no es visible. Lo que hicimos en este caso es aplicar dos conceptos de preferencia. La segunda regla prefiere, entre los atributos implícitos posibles, aquellos cuya relación está mencionada en la pregunta (si hubiera alguna). La tercer regla señala un orden de preferencia entre los atributos mismos, una vez especificada la relación. El atributo implícito preferido está marcado en negrita en la tabla \ref{table:atributos-qwords}. Si tras aplicar estar reglas siguen existiendo más de una traducción válida, entonces damos al usuario el control, pidiendo por una desambiguación.


\subsubsection*{QueryGenerator}
\label{subsubsec:query-generator}

El procedimiento para generar una query a partir de una traducción válida es exactamente el mismo que se desarrollo en \ref{subsec:closed-domain} y está implementado en el método Mapping.query().


\subsubsection*{MainProcessor}
\label{subsubsec:main-processor}

Finalmente, el punto de entrada de todo el sistema es $uba.app.MainProcessor$, que puede utilizarse especificando el parámetro -q QUESTION en cuyo caso responderá a esa pregunta y retornará el control o bien sin parámetros, en cuyo caso ingresa en un loop de preguntas-respuestas. El resultado para cada pregunta es cero, una o más queries de SQL.
Agregamos la opción de desambiguación para que el usuario elija entre dos o más queries si no se pudo generar una y también una presentación de las respuestas una vez determinada la query final, pero es más bien experimental y poco sólido.

\subsection{Ejemplos}
\label{subsec:popescu-ejemplos}

\subsubsection*{Ejemplo 1: ``Who is the head of state of Zimbabwe?''}

Consideremos nuestro primer ejemplo, una corrida trivial: ``Who is the head of state of Zimbabwe?''.

El primer paso es el tokenizer que, según expusimos, consta de los siguientes 7 pasos:

\begin{enumerate}
  \item Separar la pregunta en palabras, eliminar puntuaciones y pasar a lower case:
  \begin{itemize}
    \item \{who, is, the, head, of, state, of, zimbabwe\}
  \end{itemize}
  \item Lematizar las palabras:
  \begin{itemize}
    \item Todas las palabras ya están en su forma lematizada
  \end{itemize}
  \item Eliminar marcadores sintácticos:
  \begin{itemize}
    \item \{who, head, state, zimbabwe\}
  \end{itemize}
  \item Obtener tokens para cada lema ($Lexicon.getTokens()$)
  \begin{itemize}
    \item $getTokens(who)\ \rightarrow \{$'who'$\}$
    \item $getTokens(head)\ \rightarrow \{$ 'head country', 'head teacher body politic', 'head body politic', 'head teacher land', 'read / write head dos', 'heading provincial', 'heading state', 'heading commonwealth', 'head teacher dos', 'head teacher country', 'read / write head body politic', 'head word land', 'head state of matter', 'read / write head provincial', 'read / write head state department', 'read / write head department of state', 'head province', 'heading body politic', 'heading res publica', 'read / write head nation', (51 más)...$\}$

    \item $getTokens(state)\ \rightarrow  \{$'heart eastern united states', 'centre eastern united states', 'central eastern united states', 'centrical eastern united states', 'midsection eastern united states', 'midriff eastern united states', 'centric eastern united states', 'center eastern united states', 'middle eastern united states', 'eye eastern united states', 'camellia state yaman', 'frederick north western united states', 'compass north western united states', 'north western united states', 'second earl of guilford western united states', 'magnetic north western united states', 'northward western united states', 'due north western united states', 'union western united states', (702 más)...$\}$
    \item $getTokens(zimbabwe)\ \rightarrow \{$'zimbabwe', 'republic of zimbabwe', 'capital of zimbabwe'$\}$
  \end{itemize}
  \item Para cada token potencial (resultado del paso anterior) verificar que todos sus lemas estén presentes en el conjunto de lemas de la pregunta original.
  \begin{itemize}
    \item $getTokens(who)\ \rightarrow \{$'who'$\}$
    \item $getTokens(head)\ \rightarrow \{$'head state', 'heading state', 'head of state' $\}$
    \item $getTokens(state)\ \rightarrow  \{$  'state', 'head state', 'heading state', 'head of state'$\}$
    \item $getTokens(zimbabwe)\ \rightarrow \{$'zimbabwe'$\}$
  \end{itemize}
  \item Generar el conjunto de partes de todos los tokens hasta aquí obtenidos.
  \newline
  \{ $\emptyset$, \{'head of state', 'zimbabwe'\}, \{'zimbabwe', 'state'\}, \{'zimbabwe', 'heading state', 'state', 'head state', 'who'\}, \{'head of state', 'zimbabwe', 'who'\}, \{'head of state', 'zimbabwe', 'heading state', 'head state', 'who'\}, \{'head of state', 'zimbabwe', 'heading state', 'who'\}, \{'head of state', 'zimbabwe', 'heading state', 'state'\}, \{'head of state', 'zimbabwe', 'heading state', 'state', 'who'\}, \{'who'\}, \{'head of state', 'heading state', 'head state'\}, \{'head of state'\}, \{'state', 'who'\}, \{'head of state', 'zimbabwe', 'heading state', 'head state'\}, \{'heading state', 'state', 'who'\}, \{'heading state', 'state'\}, \{'heading state', 'who'\}, \{'head of state', 'who'\}, \{'head of state', 'zimbabwe', 'state', 'who'\}, \{'head of state', 'state', 'head state'\}, \{'zimbabwe', 'heading state', 'state', 'who'\}, \{'zimbabwe', 'head state', 'who'\}, \{'zimbabwe', 'heading state', 'who'\}, \{'head of state', 'heading state', 'who'\}, \{'state', 'head state', 'who'\}, \{'head state'\}, \{'heading state', 'state', 'head state'\}, \{'head of state', 'state', 'who'\}, \{'zimbabwe'\}, \{'state', 'head state'\}, \{'state'\}, \{'head of state', 'heading state', 'state'\}, \{'zimbabwe', 'state', 'who'\}, \{'zimbabwe', 'state', 'head state'\}, \{'head of state', 'zimbabwe', 'heading state', 'state', 'head state'\}, \{'head of state', 'zimbabwe', 'heading state', 'state', 'head state', 'who'\}, \{'head of state', 'zimbabwe', 'state', 'head state', 'who'\}, \{'heading state', 'head state', 'who'\}, \{'heading state'\}, \{'head of state', 'zimbabwe', 'state'\}, \{'head of state', 'zimbabwe', 'head state', 'who'\}, \{'head of state', 'heading state', 'state', 'who'\}, \{'head of state', 'zimbabwe', 'state', 'head state'\}, \{'head of state', 'zimbabwe', 'heading state'\}, \{'head of state', 'zimbabwe', 'head state'\}, \{'head of state', 'heading state', 'state', 'head state'\}, \{'head state', 'who'\}, \{'head of state', 'state'\}, \{'head of state', 'heading state', 'head state', 'who'\}, \{'head of state', 'heading state', 'state', 'head state', 'who'\}, \{'zimbabwe', 'heading state'\}, \{'head of state', 'head state'\}, \{'heading state', 'state', 'head state', 'who'\}, \{'zimbabwe', 'state', 'head state', 'who'\}, \{'heading state', 'head state'\}, \{'head of state', 'head state', 'who'\}, \{'head of state', 'heading state'\}, \{'zimbabwe', 'heading state', 'state'\}, \{'zimbabwe', 'heading state', 'head state', 'who'\}, \{'zimbabwe', 'who'\}, \{'zimbabwe', 'head state'\}, \{'zimbabwe', 'heading state', 'head state'\}, \{'zimbabwe', 'heading state', 'state', 'head state'\}, \{'head of state', 'state', 'head state', 'who'\} \}
  \item Para cada uno de estos subconjuntos, verificar 1) que los lemas de sus tokens cubran completamente
los lemas significativos de la pregunta original y 2) que no haya lemas repetidos
entre los tokens.
  \begin{itemize}
    \item Los lemas significativos son los obtenidos en el bullet 4: \{who, head, state, zimbabwe\}
    \item Las tokenizaciones que los cubren sin repetir lemas son: \{'who', 'head state', 'zimbabwe'\},
    \{'who', 'heading state', 'zimbabwe'\} y  \{'who', 'head of state', 'zimbabwe'\}, con lo que queda eliminado el token 'state' y las repeticiones de los tokens que refieren tanto a 'head' como a 'state', quedando solo las diferentes formulaciones sinónimas del mismo elemento de la base de datos.
  \end{itemize}
\end{enumerate}

Es decir, el Tokenizer encontró tres conjuntos de tokens completos para la pregunta, Tokenizer.generateCompleteTokenizations(``Who is the head of state of Zimbabwe?'') $\rightarrow$ [\{ `who', `head state', `zimbabwe'\}, \{`who', `heading state', `zimbabwe'\}, \{`who', `head of state', `zimbabwe'\}].

El siguiente paso es el Matcher, que construye el grafo de atributos y valores para cada uno de las tokenizaciones completas y decide si existe un conjunto de elementos de la base de datos que permita establecer la traducción. Presentamos aquí solamente el grafo para la primer tokenización completa, que puede verse en la figura \ref{grafo-1}. Las otras tokenizaciones tienen un grafo análogo y generaran el mismo resultado, que será filtrado luego por el EquivalenceChecker. Notar que no es esta repetición de tokenizaciones lo que filtra el Matcher, sino la ambigüedad introducida por un token que puede referir a dos o más elementos de la base de datos (este problema no ocurre en este primer ejemplo).
 Para construirlo, primero, se consulta al Lexicón por el tipo y los elementos asociados de cada token mediante el servicio $getMatchingElements$ como se puede ver en la tabla \ref{table:get-matching-elements-1}.
\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| p{3cm} | l | l | p{6cm} |}
\hline
Token & Tipos & Elementos & Detalle \\ \hline
zimbabwe & Value & Zimbabwe & Valor del Atributo Name de la tabla Country\\ \hline
head state, head of state, heading state & Attribute & HeadOfState & Atributo de la tabla Country\\ \hline
who & WhValue/Value & Who & Q-valor compatible con: Atributo HeadOfState de la tabla Country\\ \hline
\end{tabular}
\caption{Resultados de $getMatchingElements$ para ``Who is the head of state of Zimbabwe?''}
\label{table:get-matching-elements-1}
\end{table}
\end{center}

En este primer ejemplo el grafo no desambigua ninguna relación token-elemento ya que no hay ningún token con más de un elemento asociado, por lo que el grafo de max-flow no tiene ningún atractivo especial y es construido siguiendo el procedimiento reseñado en \ref{subsec:closed-domain} Al ejecutar el algoritmo de max-flow sobre el grafo, se obtiene que el flujo máximo es 2 y los pares generados son (Who, Country.HeadOfState), (Country.Name, Zimbabwe), sin generar ningún otro flujo alternativo como se ve en la figura \ref{grafo-1}.

\begin{figure}
\hspace*{-1.2cm}
\centering
\begin{tikzpicture}
\small
\matrix [column sep=3mm, row sep=5mm] {
   & \node (title1) [] {Tokens Valor};
   & \node (title) [] {Valores DB};
   & \node (title) [] {Atributos DB};
   & \node (title) [] {Atributos DB-2};
   & \node (title) [] {Tokens Atributo};& &

  \\
     &  \node (token_zimbabwe) [draw, shape=rectangle] {zimbabwe}; & \node (value_zimbabwe) [draw, shape=rectangle] {Name=Zimbabwe}; & \node (attr_name_1) [draw, shape=rectangle] {Name}; &  \node (attr_name_2) [draw, shape=rectangle] {Name};& & \node (i) [draw, shape=circle] {I}; &

  \\
  \node (source) [draw, shape=circle] {S}; & & & & & & & &\node (sink) [draw, shape=circle] {T};
  \\
   &  \node (token_who) [draw, shape=rectangle] {who}; & \node (value_who) [draw, shape=rectangle] {HeadOfState=Who}; & \node (attr_head_1) [draw, shape=rectangle] {HeadOfState}; &  \node (attr_head_2) [draw, shape=rectangle] {HeadOfState};&
   \node (token_head) [draw, shape=rectangle] {head state}; &
   \node (e) [draw, shape=circle] {E}; &

   \\
};
\draw[->, thick] (source) -- (token_zimbabwe);
\draw[->, thick] (token_zimbabwe) -- (value_zimbabwe);
\draw[->, thick] (value_zimbabwe) -- (attr_name_1);
\draw[->, thick] (attr_name_1) -- (attr_name_2);
\draw[->, thick] (attr_name_2) -- (i);
\draw[->, thick] (source) -- (token_who);
\draw[->, thick] (token_who) -- (value_who);
\draw[->, thick] (value_who) -- (attr_head_1);
\draw[->, thick] (attr_head_1) -- (attr_head_2);
\draw[->, thick] (attr_head_2) -- (token_head);
\draw[->, thick] (token_head) -- (e);

\draw[->, thick] (i) -- (sink) node [near end, fill=white, above] {f=1};
\draw[->, thick] (e) -- (sink) node [near end, fill=white, below] {f=1};
\end{tikzpicture}
\caption{Grafo de atributo-valor para la primer tokenización completa de ``Who is the head of state of Zimbabwe?''}
\label{grafo-1}
\end{figure}

El próximo paso es evaluar que los términos del par de tokens (`who', `head state') estén sintácticamente asociados en el
parse tree generado por el algoritmo de Charniak según nuestras reglas. El árbol sintáctico para la pregunta es el siguiente:

\begin{center}
\Tree [.S1 [.SBARQ [.WHNP [.WP \textbf{Who} ] ] [.SQ [.VP [.AUX is ] [.NP [.NP [.DT the ] [.NN \textbf{head} ] ] [.PP [.IN of ] [.NP [.NN state ] ] ] [.PP [.IN of ] [.NP [.NNP Zimbabwe ] ] ] ] ] ] [.. ? ] ] ] \\
``Who is the head of state of Zimbabwe?''
\end{center}

La regla 2 (q-word a sustantivo) vincula los términos 'who' con 'head', mientras que la 6 (términos a tokens), asocia los tokens 'who' con 'head state', cumpliendo las condiciones sintácticas requeridas por la definición de traducción válida. Por su parte, el atributo Name es implícito, lo que significa que no posee ningún token asociado y, por lo tanto, no debe cumplir la regla de traducciones válidas. Además, como no hay ninguna relación mencionada explícitamente, los tokens cubren todos los términos significativos de la pregunta y no hay ningún término repetido entre los tokens, esto significa que tenemos una (única) traducción válida para esta tokenización completa, constando de los siguiente elementos de la base de datos apareados: (Atributo Country.Name, Valor Country.Name$=$Zimbabwe), (Atributo Country.HeadOfState, Q-Valor Who).

Las otras dos tokenizaciones generan la misma traducción y sus repeticiones son eliminadas por el $EquivalenceChecker$.

Finalmente, esta única traducción pasa al $QueryGenerator$ que, aplicando las reglas descriptas en \ref{subsec:closed-domain}, genera la siguiente consulta SQL:

\medskip 
\textbf{SELECT} Country.HeadOfState \textbf{FROM} Country \textbf{WHERE} Country.Name$=$`Zimbabwe'
\medskip


Cuyo resultado es ``Robert G. Mugabe''.



\subsubsection*{Ejemplo 2: ``What caribbean countries are also considered north american?''}

Consideremos nuestro segundo ejemplo: ``What caribbean countries are also considered north american?''.

El primer paso es el tokenizer que, según expusimos, consta de los siguientes 7 pasos:

\begin{enumerate}
  \item Separar la pregunta en palabras, eliminar puntuaciones y pasar a lower case:
  \begin{itemize}
    \item \{what, caribbean, countries, are, also, considered, north, american\}
  \end{itemize}
  \item Lematizar las palabras:
  \begin{itemize}
    \item \{what, caribbean, country, is, also, consider, north, american\}
  \end{itemize}
  \item Eliminar marcadores sintácticos:
  \begin{itemize}
    \item \{what, caribbean, country, north, american\}
  \end{itemize}
  \item Obtener tokens para cada lema ($Lexicon.getTokens()$)
  \begin{itemize}
    \item $getTokens(what)\ \rightarrow \{$'what'$\}$
    \item $getTokens(caribbean)\ \rightarrow \{$'caribbean sea', 'caribbean', 'micronesia caribbean sea', 'federated states of micronesia caribbean', 'tt caribbean sea', 'micronesia / caribbean', 'tt caribbean', 'micronesia caribbean', 'federated states of micronesia caribbean sea'$\}$
    \item $getTokens(country)\ \rightarrow  \{$'country codification', 'country computer code', 'country codify', 'country code', 'baltic country', 'baltic language country', 'baltic sea country', 'north germanic language country', 'norse country', 'nordic country', 'scandinavian country', 'scandinavian language country', 'north germanic country', 'independent christian church country', 'free lance christian church country', 'self - employed person church building country', 'freelance church country', 'independent church service country', 'freelancer churchly country', 'free - lance churchly country', (149 más)...$\}$
    \item $getTokens(north)\ \rightarrow \{$'jabir aluminum ahmad aluminum jabir heart of dixie north borneo', 'jabir alabama ahmad camellia state jabir aluminum north borneo', 'jabir aluminize ahmad aluminise jabir aluminous north borneo', 'jabir aluminium ahmad camellia state jabir aluminize north borneo', 'jabir aluminize ahmad camellia state jabir aluminise north borneo', 'jabir al ahmad al jabir aluminium north borneo', 'jabir aluminous ahmad al jabir aluminise north borneo', 'jabir heart of dixie ahmad aluminous jabir camellia state north borneo', 'jabir aluminous ahmad camellia state jabir aluminous north borneo', 'jabir aluminium ahmad al jabir aluminize north borneo', 'jabir al ahmad aluminize jabir alabama north borneo', 'jabir aluminous ahmad al jabir heart of dixie north borneo', 'jabir aluminum ahmad aluminous jabir aluminum north borneo', 'jabir aluminum ahmad alabama jabir al north borneo', 'jabir heart of dixie ahmad aluminise jabir aluminous north borneo', 'jabir atomic number 13 ahmad aluminum jabir atomic number 13 north borneo', 'jabir aluminise ahmad alabama jabir aluminum north borneo', 'jabir aluminum ahmad aluminize jabir aluminize north borneo', 'jabir aluminium ahmad al jabir aluminous north borneo', 'jabir aluminous ahmad aluminium jabir camellia state north borneo', (2237 más)...$\}$
    \item $getTokens(american)\ \rightarrow \{$ 'american virgin islands', 'southward american', 'south american', 'due south american', 's american', 'dixieland american', 'dixie american', 'confederate states of america american', 'confederacy american', 'confederate states american', 'northward american', 'due north american', 'frederick north american', 'n american', 'second earl of guilford american', 'union american', 'north american', 'compass north american', 'magnetic north american', 'american - indian language spoken language', (169 más)...$\}$
  \end{itemize}
  \item Para cada token potencial (resultado del paso anterior) verificar que todos sus lemas estén presentes en el conjunto de lemas de la pregunta original.
  \begin{itemize}
    \item $getTokens(what)\ \rightarrow \{$'what'$\}$
    \item $getTokens(caribbean)\ \rightarrow \{$'caribbean'$\}$
    \item $getTokens(country)\ \rightarrow  \{$'country'$\}$
    \item $getTokens(north)\ \rightarrow \{$'north american'$\}$
    \item $getTokens(american)\ \rightarrow \{$'north american', 'american'$\}$
  \end{itemize}
  \item Generar el conjunto de partes de todos los tokens hasta aquí obtenidos.
  \newline
   \{ $\emptyset$, \{'north american'\}, \{'what', 'american', 'country'\}, \{'north american', 'what', 'american', 'country'\}, \{'american', 'caribbean'\}, \{'north american', 'what', 'american'\}, \{'what', 'country'\}, \{'north american', 'what', 'american', 'caribbean', 'country'\}, \{'caribbean'\}, \{'north american', 'what', 'caribbean'\}, \{'north american', 'american', 'country'\}, \{'north american', 'what'\}, \{'american'\}, \{'north american', 'american', 'caribbean', 'country'\}, \{'north american', 'what', 'caribbean', 'country'\}, \{'american', 'country'\}, \{'what', 'american', 'caribbean', 'country'\}, \{'north american', 'country'\}, \{'what', 'american'\}, \{'what', 'caribbean', 'country'\}, \{'american', 'caribbean', 'country'\}, \{'north american', 'caribbean'\}, \{'country'\}, \{'north american', 'what', 'american', 'caribbean'\}, \{'north american', 'caribbean', 'country'\}, \{'north american', 'what', 'country'\}, \{'what', 'caribbean'\}, \{'north american', 'american', 'caribbean'\}, \{'what'\}, \{'north american', 'american'\}, \{'what', 'american', 'caribbean'\}, \{'caribbean', 'country'\}\}
  \item Para cada uno de estos subconjuntos, verificar 1) que los lemas de sus tokens cubran completamente
los lemas significativos de la pregunta original y 2) que no haya lemas repetidos
entre los tokens.
  \begin{itemize}
    \item Los lemas significativos son los obtenidos en el bullet 4: \{what, caribbean, country, north, american\}
    \item Solo una tokenización los cubren sin repetir lemas: \{'north american', 'what', 'caribbean', 'country'\}, con lo que queda eliminado el token 'american'.
  \end{itemize}
\end{enumerate}

Es decir, el Tokenizer encontró un conjunto de tokens completo para la pregunta, Tokenizer.generateCompleteTokenizations(``What caribbean countries are also considered north american?'') $\rightarrow$ [ \{what, caribbean, country, north american\}].

El siguiente paso es el grafo del Matcher, que en este caso sí desambigua un token de valor. Como puede verse en \ref{table:get-matching-elements-2}, al token 'caribbean' le corresponden dos posibles valores: valor del atributo Region de la tabla Country y también valor del atributo Continent de la tabla Country.

En este ejemplo el grafo decide entre dos interpretaciones posibles  (Ver grafo \ref{grafo-2}) para el token 'caribbean', que puede ser un valor tanto del atributo Region como del atributo Continent. Teniendo presente el token 'north american', que solo puede tomar el atributo Continent, para maximizar el flujo el algoritmo asigna 'caribean' a Region, obteniendo un flujo de 3, que es el máximo, eliminando así la posibilidad de relacionar este token de valor con el atributo Continent.

\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| p{2cm} | p{2cm} | p{2cm} | p{6cm} |}
\hline
Token & Tipos & Elementos & Detalle \\ \hline
caribbean & Value & North America & Valor de los Atributo Region y Continent de la tabla Country\\ \hline
north american & Value & Caribbean & Valor del Atributo Region de la tabla Country\\ \hline
country & Relation & Country & Relación Country\\ \hline
what & WhValue / Value & What & Q-valor compatible con: Atributos GovernmentForm, Population, GNP, Name, Capital, LocalName, Continent, Region, Code, LifeExpectancy y SurfaceArea de la tabla Country, District, Population y Name de la tabla City e ISOfficial y Percentage de la tabla Language\\ \hline
\end{tabular}
\caption{Resultados de $getMatchingElements$ para ``What caribbean countries are also considered north american?''}
\label{table:get-matching-elements-2}
\end{table}
\end{center}

\begin{figure}
\hspace*{-1.5cm}
\centering
\begin{tikzpicture}
\footnotesize
\matrix [column sep=3mm, row sep=5mm] {
   & \node (title1) [] {Tokens Valor};
   & \node (title) [] {Valores DB};
   & \node (title) [] {Atributos DB};
   & \node (title) [] {Atributos DB-2};
   & \node (title) [] {Tokens Atributo};& & \\

   &  \node (token_what) [draw, shape=rectangle] {what}; & \node (value_what) [draw, shape=rectangle] {Country.Name[i]*=What}; & \node (attr_name_1) [draw, shape=rectangle] {Name[i]}; &  \node (attr_name_2) [draw, shape=rectangle] {Name[i]}; & & \node (e) [draw, shape=circle] {E};  & \\

   \node (source) [draw, shape=circle] {S}; & & \node (value_caribbean_2) [draw, shape=rectangle] {Continent=Caribbean}; & \node (attr_continent_1) [draw, shape=rectangle] {Continent}; &  \node (attr_continent_2) [draw, shape=rectangle] {Continent}; & & &\node (sink) [draw, shape=circle] {T}; \\

   & \node (token_caribbean) [draw, shape=rectangle] {caribbean};
   & \node (value_caribbean) [draw, shape=rectangle] {Region=Caribbean};
   & \node (attr_region_1) [draw, shape=rectangle] {Region};
   & \node (attr_region_2) [draw, shape=rectangle] {Region};
   & & \node (i) [draw, shape=circle] {I}; & \\


   & \node (token_north) [draw, shape=rectangle] {north american}; & \node (value_north) [draw, shape=rectangle] {Continent=North America}; &  & & & & \\
};

\draw[->, thick] (source) -- (token_caribbean);
\draw[->, thick] (token_caribbean) -- (value_caribbean);
\draw[->, thick] (value_caribbean) -- (attr_region_1);
\draw[->, thick] (attr_region_1) -- (attr_region_2);
\draw[->, thick] (attr_region_2) -- (i);

\draw[->, dashed] (token_caribbean) -- (value_caribbean_2);
\draw[->, dashed] (value_caribbean_2) -- (attr_continent_1);
\draw[->, thick] (attr_continent_1) -- (attr_continent_2);
\draw[->, thick] (attr_continent_2) -- (i);

\draw[->, thick] (source) -- (token_north);
\draw[->, thick] (token_north) -- (value_north);
\draw[->, thick] (value_north) -- (attr_continent_1);


\draw[->, thick] (source) -- (token_what);
\draw[->, thick] (token_what) -- (value_what);
\draw[->, dashed] (token_what) -- (value_caribbean);
\draw[->, dashed] (token_what) -- (value_caribbean_2);
\draw[->, dashed] (token_what) -- (value_north);
\draw[->, thick] (value_what) -- (attr_name_1);
\draw[->, thick] (attr_name_1) -- (attr_name_2);
\draw[->, thick] (attr_name_2) -- (i);

\draw[->, thick] (i) -- (sink) node [near end, fill=white, below] {f=3};
\end{tikzpicture}
\caption{Grafo de atributo-valor para la primer tokenización completa de ``What caribbean countries are also considered north american?''}
\label{grafo-2}
\end{figure}


Como no hay tokens de atributo explícitos, solo queda verificar la regla relacionada con los tokens de relación: Country es compatible con todos los tokens de valor que aparecen en la pregunta y, en particular, está sintácticamente asociada a what (regla 2), por lo que las condiciones de traducción válida se cumplen.

Esto nos da una única traducción válida, pero en realidad el $Matcher$ genera 16, una por cada atributo implícito posible compatible con la q-word 'What'. Notar que Country.Name no tiene ninguna particularidad especial, al menos no para el $Matcher$, sobre las demás posibilidades listadas en \ref{table:get-matching-elements-2}. Pero de esto se ocupa el $MappingFilter$ con las tres reglas especiales que agregamos. Dado que la relación $country$ está presente en la pregunta y no así las otras dos, aplicando las reglas de preferencia de atributos implícitos nos quedamos solo con la asociación Country.Name$=$What.

\begin{center}
\Tree
[.S1 [.SBARQ [.WHNP [.WP What ] ] [.SQ [.NP [.JJ caribbean ] [.NNS countries ] ] [.VP [.AUX are ] [.ADVP [.RB also ] ] [.VP [.VBN considered ] [.S [.ADJP [.JJ north ] [.JJ american ] ] ] ] ] ] [.. ? ] ] ]
 \\
Charniak parse tree para ``What caribbean countries are also considered north american?''
\end{center}

Esta única traducción pasa al $QueryGenerator$ que la traduce unívocamente en una query, aplicando las reglas descriptas en \ref{subsec:closed-domain}:
``\textbf{SELECT DISTINCT} Country.Name \textbf{FROM} Country \textbf{WHERE} Country.Continent $=$ 'North America' \textbf{AND} Country.Region $=$ 'Caribbean''' cuyo resultado es la siguiente lista:

\begin{itemize}
 \item Aruba
 \item Anguilla
 \item Netherlands Antilles
 \item Antigua and Barbuda
 \item Bahamas
 \item Barbados
 \item Cuba
 \item Cayman Islands
 \item Dominica
 \item Dominican Republic
 \item Guadeloupe
 \item Grenada
 \item Haiti
 \item Jamaica
 \item Saint Kitts and Nevis
 \item Saint Lucia
 \item Montserrat
 \item Martinique
 \item Puerto Rico
 \item Turks and Caicos Islands
 \item Trinidad and Tobago
 \item Saint Vincent and the Grenadines
 \item Virgin Islands, British
 \item Virgin Islands, U.S.
\end{itemize}

\subsection{Corridas}
\label{subsec:popescu-corridas}

Si bien dada la especificidad del dominio y la especificidad del sistema es imposible comparar resultados con otros sistemas, escribimos a mano un set de preguntas de prueba de 200 preguntas que ejecutamos sobre nuestro sistema para observar resultados.


Los resultados de la primera corrida pueden observarse en la tabla \ref{table:popescu-results-1}. 129 dieron resultados correctos: 91 dieron una única query, 27 una selección entre queries posibles (es decir, eran ambiguas) siendo esta ambigüedad razonable, 11 no generaron ninguna query, siendo esto también razonable. Respecto a las restantes 71, debemos distinguir casos. 

En primer lugar, el sistema falló en obtener respuestas de 32 preguntas por razones técnicas triviales que se corrigieron de una manera simple. La primer de estas razones es que no se pudo generar una tokenización completa por faltar alguno de los términos de la pregunta en el lexicón y en el diccionario de stopwords. Para solucionar esto agregamos algunas palabras al diccionario de stopwords a mano, aunque, claro, este procedimiento no escala. Es interesante notar en este punto que, en los trabajos sobre los que nos basamos, no están definidas las reglas para generar sinónimos a partir de Wordnet (simplemente se menciona que se usa Wordnet, pero Wordnet tiene diferentes maneras de generar sinónimos a partir de una palabra) y tampoco está definido ningún mecanismo para generar el diccionario de stopwords (solo se menciona que es independiente de la DB y que está hecho a mano). Así, una formalización teórica y una evaluación de diferentes mecanismos de generación de sinónimos y de stopwords quedará como trabajo futuro. Ambos, junto con la definición de reglas de análisis sintáctico serían las tres áreas más abiertas y disponibles para formalizar en este modelo teórico. Volviendo a los resultados: resolvimos este primer caso agregando al diccionario de stopwords algunas palabras. En segundo lugar, tenemos que la qword What no estaba relacionada con algunos atributos (como Language e IndependenceYear). Habíamos restringido la compatibilidad de What con algunos atributos para intentar minimizar el hecho de que What parece ser compatible con todos los atributos, dependiendo el fraseo de la pregunta. En una segunda corrida, agregamos las relaciones de compatibilidad de What con estos atributos. Con estos dos cambios, las 32 preguntas que estamos considerando en este párrafo dieron como resultados 23 respuestas correctas exactas y las 9 restantes son 6 inherentemente ambiguas, 3 ambiguas por un problema del modelo que mencionaremos en el próximo párrafo.

%1 ambigua por EC
%6 ambigua OK
%2 ambigua por Country == CountryLocalName



\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| r |  p{12cm}}
\hline
Total & Categoría \\ \hline
91 & Respuesta exacta \\ \hline
27 & Ambiguas inherentemente + pedido de reformulación \\ \hline
11 & Sin respuesta (razonable, fuera de scope) \\ \hline
32 & Fallas simples en stopwords o en lexicón \\ \hline
10 & Ambiguas por problemas de sinonimia en el modelo \\ \hline
4 & Ambiguas. Problemas del lexicón. \\ \hline
6 & El analizador sintáctico no encontró asociación. \\ \hline
19 & Problemáticas. Análisis más detallado en texto. \\ \hline
200 & Total \\ \hline

\end{tabular}
\caption{Resultados de la primera corrida sobre las preguntas de test}
\label{table:popescu-results-1}
\end{table}
\end{center}


Las 10 notadas en la tabla como \sq{Ambiguas por modelo} son problemas de ambigüedad que refieren a cierta redundancia entre el modelo de la DB y los sinónimos. Consideremos la pregunta \sq{When did Yugoslavia become independent?}, que el sistema reconoce como ambigua y ofrece las dos siguientes opciones:
\begin{itemize}
  \item SELECT DISTINCT Country.IndependenceYear FROM Country WHERE Country.LocalName = 'Jugoslavija'
  \item SELECT DISTINCT Country.IndependenceYear FROM Country WHERE Country.Name = 'Yugoslavia'
\end{itemize}

El problema aquí es que el lexicón generó el token Yugoslavia como correspondiente tanto al valor 'Yugoslavia' para Country.Name y para el valor 'Jugoslavija' para Country.LocalName. Este problema ocurre también con Country.Code (por ejemplo, United States es un token para USA y para United States). No vemos una solución general, más allá de establecer que, en caso de ser las diferentes opciones una variación de la misma query sobre Country.LocalName, Country.Name y Country.Code, entonces el $MappingFilter$ se queda solo con aquella que menciona Country.Name (esta modificación ya fue presentada en la sección \allref{subsec:popescu-codigo}). Con estos cambios, todas las preguntas en esta categoría se convierten en exactas (10 de la primer corrida y 3 que en la primera corrida tenían un problema con el tokenizer que al ser corregido generó este problema).


Con estas dos correcciones, realizamos la segunda corrida, cuyos resultados pueden observarse en la tabla \ref{table:popescu-results-2}


\begin{center}
\begin{table}[h]
\centering
\begin{tabular}{| r |  p{12cm} |}
\hline
Total & Categoría \\ \hline
126 & Respuesta exacta \\ \hline
34 & Ambiguas inherentemente + pedido de reformulación \\ \hline
11 & Sin respuesta (razonable, fuera de scope) \\ \hline
4 & Ambiguas. Problemas del lexicón. \\ \hline
6 & El analizador sintáctico no encontró asociación. \\ \hline
19 & Problemáticas. Análisis más detallado en texto. \\ \hline
200 & Total \\ \hline

\end{tabular}
\caption{Resultados de la segunda corrida sobre las preguntas de test}
\label{table:popescu-results-2}
\end{table}
\end{center}

Las 4 distinguidas en ambas tablas como \dq{Ambiguas. Problemas del lexicón.} refieren a sinónimos demasiado amplios dados a ciertos elementos. En concreto, estas 4 son ambiguas porque el lexicón tiene una correspondencia entre el token \sq{republic} y el valor \sq{Commonwealth of the US}. Esto se solucionaría con la supervisión del lexicón o, más en general, mejorando el módulo.

Las 6 que fallaron por el análisis sintáctico refieren, en efecto, a problemas de analizador sintáctico, que, como ya mencionamos, tiene enormes limitaciones ya que no fue definido por un experto sino a prueba y error. Desactivando el análisis sintáctico, estas 6 preguntas se convierten en exactas. 

Sobre las 20 problemáticas pasaremos revista a continuación.

Hay seis preguntas con sentido semántico dentro del espacio de sentido del sistema, pero cuya forma no tiene ningún flujo para especificarse. Por ejemplo, es el caso de \sq{Who is Islam Karimov?}, que como respuesta debería tener "ser el líder de X país", es decir, devolver el nombre del atributo tal que existe un valor para una fila, flujo que no existe en este modelo. Otra pregunta así es \sq{What countries of the British Islands are independent?} (curiosamente escrita poco tiempo antes del brexit), que no logra encontrar una respuesta porque no sabe decidir que \sq{Tener un valor no nulo en Independence Year} implica \sq{ser independiente}. \sq{What is the population of the capital of Germany?} también falla, debido a que no soportamos más de un join y eliminamos la navegabilidad entre capital de un país y su fila en la tabla ciudades. 

\sq{How many people live in Kabul?} genera, para \sq{live} diferentes tokens relacionados con LifeExpectancy (getTokens('live') stem=live--> ['live anticipation', 'live expectancy', 'living expect', 'living anticipation', 'live expect', 'live expectant', 'living expectant', 'living expectancy']) pero luego la otra palabra no aparece (con razón). Lo razonable aquí sería que live sea a la vez una palabra de un token y una stopword. El modelo no soporta esto, por lo que no encuentra tokenización ni respuesta para esta pregunta.

Para \sq{What is the surface of Afghanistan?} no encuentra ningún token para surface, cuando debería encontrar \sq{surface area}. Esto podría resolverse agregando a mano al TokenAugmenter el término surface para surface area.

Para \sq{What languages do the frenchs speak?}, el término french se asoció al lenguaje y no a \sq{los habitantes del país France} sin poder generar una respuesta.

Dos se corrigieron con las correcciones técnicas.


\sq{What is the population of the district named Qandahar?} es interesante porque \sq{name} funciona como token y hace que el sistema no logre encontrar un máximo flujo 

Para \sq{In which region is Rome?}, \sq{Who is the head of state of Bielorussia?}, \sq{What is the population of the country lead by Hugo Chavez?} el lexicón no disponía de tokens para Rome ni para Bielorussia ni para Hugo Chavez (pero si para Roma, Belarus y Hugo Chávez Frías)

Por otro lado, el sistema no soporta diferentes preguntas, por ejemplo: no soporta ORS y una pregunta era \sq{What cities are located in Italy or in Germany?}, no soporta manejo de números y una pregunta era \sq{Which countries have a surface area bigger than 65610.00?}.

Como conclusión tras analizar estas 20 preguntas problemáticas podemos decir que el modelo tiene limitaciones importantes tanto a nivel estructural como en el nivel de la definición concreta del lexicón, el diccionario de stopwords y el analizador sintáctico. Sin embargo, esto no debe quitar el foco de atención de la cantidad de respuestas dadas correctamente, las inherentemente ambiguas interpretadas como tales, las imposibles de procesar que son correctamente rechazadas y, finalmente, aquellas que mostraron límites técnicos triviales y de fácil solución, que sugieren que un trabajo más exhaustivo y puntilloso en la definición y supervisión de los diferentes conjuntos de palabras disponibles pueden redundar en un incremente sustancial sencillo de la performance del sistema.


\subsection{Conclusiones, limitaciones y trabajo futuro}
\label{subsec:popescu-cierre}

El sistema implementado consiste en un mecanismo para traducir preguntas simples formuladas en inglés a las consultas SQL correspondientes sobre la base de datos World, permitiendo reconocer cuando una pregunta no es semánticamente tratable. Si bien es verdad que la implementación require de desarrollo humano, los tiempos de adaptación a diferentes bases de datos, con el código base existente, no son tan grandes. El potencial de los sistemas de dominio cerrado basados en traducciones a SQL tiene un interés acotado ya que su concepto es, en realidad, un agregado cosmético para una base de datos ya existente y ya consultable. Dicho de otro modo: la información sobre la que trabajamos en este caso ya está ordenada y estructuradas y es accesible, consultable, mediante un lenguaje: el SQL, que, con sus limitaciones y su tiempo de aprendizaje, es un lenguaje comprensible por humanos. Con esto en mente, el agregado que introduce un módulo de question answering sobre esta información está en proponer una interfaz más intuitiva. Este agregado, técnicamente menor, incorpora, sin embargo, un aporte clave, que es la accesibilidad de las bases de datos a un público masivo, conocedor de su idioma (inglés en este caso, pero en general, de algún idioma) pero no del SQL. Como ya mencionamos, esta posibilidad, en combinación con un procesador de voz, tiene un interés esencial.

Por otro lado, creemos que es clave destacar una hipótesis de trabajo de Popescu que nos parece fundamental a la hora de enfocar el trabajo sobre el área de question answering sobre dominios cerrados y estructurados. Esta hipótesis es: no es necesario entender todas las preguntas posibles formulables en lenguaje natural, ya que estas pueden tener una complejidad arbitrariamente grande; basta con limitarse a definir un conjunto de preguntas simples tratables que, sin embargo, permita una amplia expresividad y, más aún, que sea, en la práctica, la forma más natural y directa de formular esta pregunta.
Creemos que esta hipótesis de trabajo es muy fecunda y prolífica, ya que elimina de raíz el preconcepto de que es imposible traducir el lenguaje natural informal en un lenguaje técnico formal. Quizás sea imposible computacionalmente capturar el sentido de la frase \dq{explicar con palabras de este mundo que partió de mí un barco llevándome} de Alejandra Pizarnik, pero definitivamente es computable traducir la pregunta \dq{¿En qué año murió Alejandra Pizarnik?} a una consulta SQL de la forma ``\textbf{SELECT} dead\_year \textbf{FROM} writers \textbf{WHERE} name $=$ `Alejandra Pizarnik' ''. Si bien el ejemplo es un poco excesivo en su contraste, consideramos que este exceso hace más patente la importancia de esta hipótesis de trabajo al señalar, digamos, \textit{zonas} computacionales del lenguaje, en particular, del conjuntos de las preguntas.

El sistema que presentamos en nuestro trabajo incorpora todos los conceptos del marco teórico propuesto por Popescu, permitiendo distinguir preguntas semánticamente tratables de aquellas que no lo son. Con ciertas limitaciones que presentamos durante la exposición y que en breve mencionaremos resumidamente, es un sistema funcional que sirve como base de trabajo para proyectos futuros de mayor solidez y envergadura y, por qué no, para un trabajo conjunto con el área de procesamiento de voz del Departamento.

Las diferentes limitaciones y mejoras de nuestra implementación fueron mencionadas durante la exposición de la misma que realizamos a lo largo de este capítulo: a continuación las presentamos juntas para facilitar su acceso.

En un nivel técnico, habría una enorme mejora de performance implementando el lexicón sobre una base de datos relacional. Los archivos json sirven para un modelo de escala pequeña, pero no permiten escalar ya que genera un tiempo de carga innecesario, así como también uso de memoria. Existen también una serie de clases con datos dentro del código que deberían separar archivos de configuración de códigos. Estas son TokenAugmenter, WhGenerator y Config. Estas clases requieren editar el código para aplicarlo sobre una nueva base de datos, cuando en realidad solo es necesario editar definiciones.

Más allá de estas mejoras técnicas, las siguientes mejoras permitirían incrementar la usabilidad y la eficacia del sistema:

\begin{itemize}
\item En el Lexicón, no generar sinónimos para nombres propios. Wordnet posee sinónimos para, por ejemplo \textit{Hugo} (Victor Hugo, etc) introduciendo ruido innecesario y fácilmente eliminable.
\item En el Lexicón, agregar un desambiguador de sentidos para los sinónimos de los tokens. Este es un problema complejo de NLP e integrar una solución del mismo dentro del modelo ya definido podría redundar en un avance teórico. Desde un nivel más técnico y con menor complejidad, también sería posible implementar un desambiguador supervisado.
\item Soportar diferentes paths para aparear (\textit{joinear}) tablas.
\item Soportar tokens multi tipados en el Matcher.
\item Soportar desambiguación de relaciones en el Matcher.
\item Interfaz con el usuario: como mencionamos, el resultado es una query y la desambiguación es entre dos o más queries. Que el resultado sea una respuesta presentada en un formato amigable y que la desambiguación sea, también, presentada en un formato amigable es una mejora de usabilidad necesaria para utilizar el sistema en la vida real.
\item CharniakParseTree: evaluando con un lingüista profesional las reglas utilizadas para definir la \textit{asociación sintáctica} seguramente se obtengan reglas más eficaces.

\end{itemize}

Con esta lista terminamos la presentación de nuestro sistema closed domain en inglés. En el próximo capítulo daremos vuelta la página y presentaremos nuestro sistema open domain multilingüe.
