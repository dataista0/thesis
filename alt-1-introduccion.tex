
\chapter{Introducción}
\label{chap:intro}\label{chap:1}


\section{Qué es question answering}
\label{sec:que-es-qa}

Question answering es un área de ciencias de la computación que busca generar respuestas concretas a preguntas expresadas en algún lenguaje natural. Es un área compleja que combina herramientas de búsqueda y recuperación de la información (\textit{information retrieval}), de procesamiento del lenguaje natural (\textit{PLN}) y de extracción de información (\textit{information extraction}). Por poner un ejemplo: para el input \textit{\dq{?`Cuándo nació Noam Chomsky?}} un sistema de question answering podría devolver \dq{\textit{7 de diciembre de 1928}}.
Este área representa el paso lógico posterior a los sistemas de recuperación de documentos y logró en los último años una serie de hitos impulsados por el proyecto general de la web semántica. Watson, el sistema desarrollado por IBM que derrotó a los mejores competidos de Jeropardy! en tiempo real\footnote{En esta url está disponible el programa en el que el sistema vence a sus competidores humanos: \url{http://www.youtube.com/watch?v=WFR3lOm_xhE}} sea el ejemplo más visible, pero incluso buscadores como Bing! y Google comienzan a incorporar este tipo de algoritmia.

Los sistemas de question answering suelen ser sistemas complejos que abordan distintas problemáticas: por un lado deben definir y optimizar la base de conocimiento para el dominio dado, por otro deben realizar un análisis de las preguntas en lenguaje natural a fin de volverlas
tratables computacionalmente y, finalmente, deben poder buscar -o generar- y decidir la mejor respuesta para la pregunta ingresada, si es que esa respuesta existe.

Algunos de estos subproblemas tienen nombre propio en la literatura y son, por así decirlo, toda un área aparte. Por ejemplo, dependiendo de la amplitud de la base de conocimiento, un sistema es de dominio cerrado (\textit{closed domain}), si la base es acotada a un dominio de la realidad específico. Por el contrario se llama de dominio abierto (\textit{open domain}), si no lo es, es decir, si se espera que sepa responder preguntar de cualquier dominio. Por su parte, dominios de conocimiento más pequeños, en general, requieren y permiten un modelado más exhaustivo
de los datos y un análisis más estructurado, mientras que dominios de conocimiento más abiertos suelen
tener un enfoque apoyado más fuertemente en el análisis lingüístico cuantitativo.

Otra distinción usual contempla el tipo de datos de la base de conocimiento:  puede ser estructurado, como en una base de datos
relacional, semi-estructurado, como los documentos XML, o también sin estructura, como el texto plano. Cada tipo de datos tiene su enfoque:
los datos estructurados definen una ontología acotada que limita qué cosas se pueden preguntar y, en consecuencia, qué cosas se pueden responder: el problema en este caso consiste en traducir la pregunta formulada en un lenguaje humano a una query definida en el modelo de datos. Por otro lado, si los datos no tienen estructura, no es posible definir una ontología rígida y se hace necesario otro tipo de enfoque más difuso y basado en análisis lingüísticos del corpus de datos mismo contra la pregunta. No siempre,  pero en general una base de conocimiento closed domain está asociada a un tipo de datos estructurado o semi-estructurado, mientras que las bases open domain
suelen ser no estructuradas.

Otro tipo de clasificación se centra en el tipo de preguntas que los sistemas saben responder. Los tipos más conocidos son las factoids -o fácticas-, que refieren a hechos fácticos (¿Cuándo ocurrió ...? ¿Cuántos hijos tiene...? ¿En dónde vivía Y en el año ...?), las listas (¿Qué libros escribió Nietzsche entre 1890 y 1900?)y las definiciones (¿Qué es un huracán?). Otros tipos usuales son las preguntas por un modo (¿Cómo...?), por una razón (¿Por qué...?) y, en general, pueden agregarse subclasificaciones como dependencias temporales explicitas o dependencias semánticas con otras preguntas.
Existe un consenso general a la ahora de definir el modelo de software más abstracto o de arquitectura para encarar la construcción de un sistema de question answering. Esta arquitectura consiste en un pipeline con al menos tres módulos o compotentes bien diferenciados:
\begin{itemize}
\item Módulo de procesamiento de la pregunta
\item Módulo de procesamiento de documentos
\item Módulo de procesamiento de la respuesta
\end{itemize}
Cada uno de estos módulos cuenta a su vez con subcomponentes sobre los cuales hay mayor o menor consenso, que determinan, en definitiva, la performance del sistema concreto implementado. Típicamente, un sistema de question answering de dominio abierto dispondrá, mínimanente, de un clasificador de preguntas en su módulo de procesamiento de preguntas, de uno a más sistemas de recuperación y filtrado de información en su modulo de procesamiento de documentos y de diferentes heurísticas en su módulo de procesamiento de respuesta. En \allref{chap:estado-de-arte} veremos con detalle los enfoques arquitecturales usuales del área y los componentes típicos de cada módulo. 


\section{Proyecto de la tesis}
\label{sec:proyecto}

En esta tesis investigamos los distintos problemas que se subsumen bajo el concepto general de question answering y reseñamos diferentes soluciones y modelos aplicados para resolverlos, bajo el proyecto de la implementación de dos modelos de question answering: uno de dominio cerrado (específico) y datos estructurados vinculados con el proyecto Mitic y con adaptaciones bilingües y otro sistema multilingüe, de dominio abierto y que utiliza como corpus las wikipedias de diferentes idiomas. Para el primer modelo orientamos nuestro desarrollo de acuerdo al modelo teórico general y simplificado del paper \cite{QADB1} e implementamos soluciones para un conjunto restingido de preguntas. Para el segundo modelo utilizamos   un subconjunto de los problemas de la competencia CLEF '07 y desarrollamos el sistema utilizando como baseline el framework Qanus, adaptándolo para utilizar herramientas de procesamiento de lenguajes multilingües de la librería Freeling. 

Mientras el enfoque estructurado resulta imposible de evaluar debido a su dominio acotado, sí resulta posible realizar experimentos sobre las herramientas al utilizarlas en el modelo no estructurado, gracias a las distintas competencias cuya razón de ser es, justamente, la creación de criterios únicos de evaluación al nivel de la comunidad de investigadores del área. Los resultados tangibles de esta tesis son dos modelos de software con diferentes soportes para idiomas: un modelo básico de question answering como interfaz a la base de datos del proyecto Mitic, con algunas funciones bilingües y un modelo no estructurado de dominio abierto, completamente multilingüe, que resuelve algunas subtareas de la competencia Clef '07.


Por un lado, disponemos de una base de datos estructurada, con datos del área de la investigación y la
producción en TICs en Argentina, que requiere un enfoque estructurado con métodos basados en ontologías y en 
formalizaciones de dominio. El enfoque aquí es traducir la pregunta formulada en lenguaje humano a un lenguaje más
formal ``comprensible" según el modelo de dominio. 

Por otro lado, para evaluar métodos de QA para datos no estructurados, resolvimos algunos problemas de la competencia CLEF del '07. La base de conocimientos para
estos ejercicios son algunos snapshots de Wikipedia en español, inglés y portugués anteriores al 2007. Sobre esta base de conocimiento,
el enfoque no es traducir la pregunta a un lenguaje estructurado sino interpretarla y compararla, mediante distintas métricas, 
con documentos y pasajes, buscando medidas estádisticas y otras condiciones que permitan \textit{rankear} una respuesta candidata
con un cierto grado de confianza, o bien determinar que no fue posible encontrar una respuesta para la pregunta. 


Conceptualmente, los modelos consisten en tres pasos típicos: la creación de la base de conocimientos optimizada, el análisis
lingüístico de la pregunta y la generación de una respuesta desde la base de conocimientos optimizada a partir de la pregunta con sus
anotaciones. Los pasos 1 y 2, la generación de la base de conocimientos optimizada y el procesamiento de la pregunta son procesos
esencialmente análogos para la base de conocimientos estructurada y para la no estructurada. El tercer paso, la generación de respuestas,
tiene distintos enfoques según el caso. 


Con un poco más de detalle, la implementación del modelo de dominio cerrado está vinculada con un marco de trabajo común entre el Grupo de Autómatas, Lenguajes, Lingüística e Información (GALLI)\footnote{\url{http://www.galli.dc.uba.ar/}}, del Departamento de Computación de la Facultad y la Fundación Sadosky\footnote{\url{http://www.fundacionsadosky.org.ar/}}, relacionado con la construcción de una base de conocimiento y la recuperación de la información en el dominio de la investigación y la producción relacionada con TICs en Argentina: el proyecto Mitic. Mitic\footnote{\url{http://www.fundacionsadosky.org.ar/es/Programas-Proyectos/quien-es-quien\#mitic}} es una plataforma web que permite buscar investigadores, empresas, universidades, proyectos y organismos que se encuentren trabajando en temáticas relacionadas con las TIC, y explorar además las relaciones existentes entre ellos. El grafo de relaciones generado por este proyecto es la base de datos sobre la que trabajamos en la sección closed domain de esta tesis. La base de conocimiento generada es estructurada y consta de una serie de entidades: investigadores, universidades, publicaciones, proyectos, empresas y temáticas, con diferentes tipos de relaciones. Esta base de conocimiento está definida como un grafo de relaciones con diferentes pesos y valores entre las entidades, a partir de lo que originalmente era una recopilación heterogénea de datos en varios formatos. El grafo de Mitic tiene relaciones directas y también inferidas, con un cierto grado de confiabilidad (peso) para cada relación. Tomando como punto de
partida esta base de conocimiento, este proyecto se propone construir un sistema de question answering bilingüe de dominio cerrado, expandible a más idiomas.
Para esto, definimos sobre la base de conocimiento un modelo rígido, que determina un conjunto acotado de preguntas tratables, y utilizamos herramientas de procesamiento de lenguaje natural para clasificar las consultas del usuario dentro de este esquema. Para este modelo, definimos una interfaz única para las entidades que permite la integración de nuevos tipos con un esfuerzo mínimo. La base de datos está principalmente en español, solo algunos títulos y resúmenes de publicaciones están en inglés, pero los tokens que utilizamos para dirigir el flujo de información son formales y no tienen idioma.

Para la traducción o el mappeo de la pregunta a esta esquema utilizamos analizadores de distintas librerías, descriptas en \allref{chap:teorico} y en \allref{chap:herramientas}. En particular, ver \allref{sec:freeling}, librería de procesamiento de lenguaje natural multilingüe, que es la principal herramienta utilizada a la hora de traducir preguntas en distintos idiomas al mismo lenguaje formal. La base de datos con la que comenzamos era una serie de XMLs que requerían un esfuerzo de modelado bastante alto. Posteriormente trabajamos con una base de datos en Mongdb dónde los modelos estaban mucho mejor definidos.


Por su parte, para desarrollar y evaluar mecanismos de dominio abierto resolvimos algunos ejercicios de la competencia de question answering organizada por CLEF 
en 2007. CLEF (de \textit{Cross-Language Evaluation Forum}) es una organización que busca fomentar la investigación en sistemas de information retrieval cross-language. En particular, una vez por año CLEF lanza una competencia de Question Answering multilingüe, con diferentes corpus y diferentes tipos de ejercicios. Estas competencia permiten obtener un patrón estándar de comparación entre distintos desarrollos y una idea general del estado de arte alcanzado en cada área.
Por ejemplo, la competencia ya finalizada del año 2013, QA4MRE@CLEF2013, (Question Answering for Machine Reading Evaluation) se enfoca principalmente en Machine Reading, tarea que incluye un grado de razonamiento elevado para la computadora\footnote{\url{http://celct.fbk.eu/QA4MRE/}}.

Existen distintas conferencias de evaluación de sistemas QA o de subtareas asociadas (por ejemplo TREC - Text Retrieval Conference \footnote{\url{http://trec.nist.gov/}}-, TAC - Text Analysis Conference \footnote{\url{http://www.nist.gov/tac/}}) - y, a su vez, estas distintas competencias ofrecen distinos llamados a competencias. Elegimos resolver una tarea de la competencia Clef '07  por varias razones (Ver \cite{GuidelineClef07} y \cite{OverviewClef07} para un detalle exhaustivo de la conferencia en cuestión). La razón principal fue la pertinencia de la tarea a evaluar al scope de esta tesis. Muchas competencias exigen un grado de complejidad que excede por mucho lo que puede alcanzarse en el tiempo estimado de una tesis de licenciatura y, si bien tuvimos que recortar ciertos aspectos de las tareas a fin de implementar este proyecto en tiempo y forma, estos aspectos fueron pocos.
Otra razón fue la disponibilidad y el atractivo de la base de conocimiento para estos ejercicios: utilizan snapshots de wikipedia. 
La competencia del '07 ofrece dos tipos de tareas:
\begin{itemize}
\item Monolingue: donde el idioma de la pregunta y el idioma de la fuente de información son el mismo
\item Cross-lingual: donde el idioma de la pregunta y el idioma de la fuente de información difieren
\end{itemize}
Las tareas consideran los siguientes idiomas: inglés, búlgaro, alemán, español, italiano, francés, holandés, rumano y portugués. Por su parte, algunos problemas utilizan corpus de datos privados de la competencia y otros utilizan como fuente las distintas wikipedias. De los proeblemas que utilizan
wikipedia, implementamos un sistema que responde las preguntas en español, mono-idioma, es decir, ejercicios con preguntas formuladas en español que se responden en base a la wikipedia en español e hicimos lo mismo para el portugués. A su vez, implementamos esta misma solución para el inglés, dado que estaban disponibles las preguntas y señalados los links a los snapshots de wikipedia en inglés, pero no fue posible evaluar sus resultados debido a que las respuestas esperadas no estaban disponibles online y no obtuvimos respuesta de los organizadores de la competencia. El uso estructural de la librería freeling permite que la implementación de soluciones para otros idiomas mediante el set-up del corpus en el idioma y una pequeña configuración. 
Los ejercicios elegidos constan de 200 preguntas agrupadas. Los grupos de preguntas refieren a un tema, inferible a partir de la primer pregunta.
Por ejemplo, el primer grupo de preguntas es:
\begin{itemize}
\item ¿En qué colegio estudia Harry Potter?
\item ¿Cuál es el lema del colegio?
\item ¿En qué casas está dividido?
\item ¿Quién es el director del colegio?
\end{itemize}
Es decir, para cada grupo se debe inferir el \dq{tema} en la primer pregunta para arrastrarlo a la hora de responder las siguientes. Más allá de esta particularidad,
las preguntas son preguntas simples. Más adelante haremos un análisis de las mismas con más detalle.


\subsection{Estructura de la tesis}
\faltadependiente
La tesis se articula de la siguiente manera: En la Introducción (\ref{chap:1}), cerrandose en estos parrafos, realizamos en primer lugar una introducción mínima al área del question answering (\ref{sec:que-es-qa}) y en segundo lugar mecionamos los alcances de esta tesis (\ref{sec:proyecto}). 

En el siguiente capítulo (\ref{chap:teorico}) recorreremos los conceptos generales de algunas áreas en las que se apoya question answering, repasando primero alguna terminología básica (\ref{sec:terminologia}) para pasar luego a comentar estructuras típicas de recuperación de la información (\ref{sec:information-retrieval}) y, finalmente, de procesamiento de lenguajes (\ref{sec:nlp}) aplicado a problemas de question aswering. 

En el capítulo III (\ref{chap:estado-de-arte}) pasamos revista general del estado de arte del área. Primero realizamos una introducción general (\ref{sec:intro-general-qa}), considerando la historia de la disciplina, las competencias en las que la investigación se nucleó (\ref{subsec:historia}) y las métricas utilizadas por estas competencias para evaluar a los competidores (\ref{subsec:metricas}), luego hacemos un recorrido de diferentes enfoques, considerando el estado de arte académico para dominio abierto (\ref{subsec:open-domain}) y dominio cerrado (\ref{subsec:closed-domain}) y finalmente, el comercial, reseñando el funcionamiento de Watson de IBM (\ref{subsec:ibm-watson}).

En los siguientes capítulos presentamos los modelos implementados. En el IV (\ref{chap:4}) comentamos el modelo de dominio cerrado para la base de datos  Mitic, presentando primero la base de conocimientos y su API espeficica de acceso (\ref{sec:grafo-mitic}), el proceso de anotado de preguntas (\ref{sec:qp-mitic}) y los mecanismos de traducción implementados (\ref{sec:ar-mitic})
En el V (\ref{chap:5}) presentamos el modelo de dominio abierto para las wikipedias de diferentes idiomas, presentando en primer lugar los problemas seleccionados de la competencia Clef '07 (\ref{sec:ejecicio-de-clef}), en segundo lugar la implementación baseline de Qanus, las adaptaciones multilingües y demás mejoras realizadas (\ref{sec:sistema}) y, finalmente, los diferentes experimentos que realizamos sobre este baseline y sus mejoras (\ref{sec:eval}).

\faltadependiente

% El trabajo se estructura de la siguiente manera. En el capítulo \allref{chap:teorico} se hará una breve introducción terminológica y conceptual algunas de las  herramientas principales de information retrieval y procesamiento de lenguaje natural utilizadas en esta tesis, complementada por el detalle técnico más concreto expuesto en \allref{chap:herramientas}. En el capítulo \allref{chap:estado-de-arte} pasamos revista de varias implementaciones de sistemas de question answering, haciendo especial foco en el sistema de IBM -Watson- y de su arquitectura DeepQA como ejemplo de un proyecto exitoso de question answering, mientras también comentamos otros sistemas -Qanus, OpenEphyra, Aranea y Just.Ask-, haciendo énfasis en Qanus, debido a que su uso en un modelo inicial del proyecto. Finalmente, en el capítulo \allref{chap:implementacion} describiremos nuestra implementación de los modelos closed y open domain para la base de datos de Mitic y para los ejercicios de la competencia CLEF '07.